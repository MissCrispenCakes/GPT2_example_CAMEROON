{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MissCrispenCakes/GPT2_example_CAMEROON/blob/main/May-Copy_of_GPT_2_cameroon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhQsu-RQQXWG"
      },
      "source": [
        "# GPT-2 Example\n",
        "\n",
        "## Here we will run through the popular GPT-2:\n",
        "\n",
        "GPT-2 is a neural-network-powered language model. A language model is a model that predicts the likelihood of a sentence existing in the world. For example, a language model can label the sentence “I take my dog for a walk” as more probable to exist (i.e. on the Internet) than the sentence “I take my banana for a walk.” This is true for sentences as well as phrases and, more generally, any sequence of characters.\n",
        "\n",
        "Like most language models, GPT-2 is elegantly trained on an unlabeled text dataset (in this case, the training data includes among others Common Crawl and Wikipedia). Words or phrases are randomly removed from the text, and the model must learn to fill them in using only the surrounding words as context. It’s a simple training task that results in a powerful and generalizable model.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pzxl1vYX-1kk"
      },
      "source": [
        "Setup:\n",
        "\n",
        "1) Make sure GPU is enabled, go to edit->notebook settings->Hardware Accelerator GPU\n",
        "\n",
        "2) Make a copy to your google drive, click on copy to drive in panel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW0abT07ZkhZ"
      },
      "source": [
        "Note: Colab will reset after 12 hours make sure to save your model checkpoints to google drive around 10-11 hours mark or before, then go to runtime->reset all runtimes. Now copy your train model back into colab and start training again from the previous checkpoint."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLXW02eIYpcB"
      },
      "source": [
        "clone and cd into repo\n",
        "\n",
        "\n",
        "---\n",
        "# FOR NOW I AM USING MY PUBLIC REPO CLONE - WE CAN CLONE INTO THE CAMEROON GITHUB>?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICYu3w9hIJkC",
        "outputId": "04d5e9b6-7c05-4952-a9d3-967e6ca8e8f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'GPT2_example_CAMEROON'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 55 (delta 25), reused 9 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (55/55), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/MissCrispenCakes/GPT2_example_CAMEROON.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eEIs3ApZUVO"
      },
      "outputs": [],
      "source": [
        "%cd GPT2_example_CAMEROON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtn1qZPgZLb0"
      },
      "source": [
        "Install requirements.\n",
        "\n",
        "We will use an earlier version of TensorFlow than we have been using for our labs so far - this will make it easier for you to play around with the introductory content that exists online. (If time will update/transfer to newer TF - don't worry about the 'incompatible' flags - they get resolved)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "434oOx0bZH6J",
        "outputId": "106f9f76-1b84-4abb-a0e9-9ce292489cad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-gpu==1.15.0 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.4.4, 2.5.0, 2.5.1, 2.5.2, 2.5.3, 2.6.0, 2.6.1, 2.6.2, 2.6.3, 2.6.4, 2.6.5, 2.7.0rc0, 2.7.0rc1, 2.7.0, 2.7.1, 2.7.2, 2.7.3, 2.7.4, 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-gpu==1.15.0\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.15.0rc3 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.4.4, 2.5.0, 2.5.1, 2.5.2, 2.5.3, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0, 2.6.1, 2.6.2, 2.6.3, 2.6.4, 2.6.5, 2.7.0rc0, 2.7.0rc1, 2.7.0, 2.7.1, 2.7.2, 2.7.3, 2.7.4, 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==1.15.0rc3\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fire>=0.1.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (0.5.0)\n",
            "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (2017.4.5)\n",
            "Requirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (2.21.0)\n",
            "Requirement already satisfied: tqdm==4.31.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (4.31.1)\n",
            "Requirement already satisfied: toposort==1.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (1.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2022.12.7)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (2.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install tensorflow-gpu==1.15.0\n",
        "!pip3 install tensorflow==1.15.0rc3 --force-reinstall # https://files.pythonhosted.org/packages/fe/a7/b2db9e94920efea59877476cd2ba239dbd5fb631f861a2785dd2c24a8a24/tensorflow-1.15.0rc3-cp36-cp36m-manylinux2010_x86_64.whl\n",
        "!pip3 install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvUQhgK3PQ4L"
      },
      "source": [
        "Mount drive to access google drive for saving and accessing checkpoints later. Have to log in to your google account - you may already be connected from Lab 9, run this anyway to check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNpf6R4ahYSN",
        "outputId": "46be6870-c8bb-4d74-bb31-ad46889f88f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn4pHq1m4SaA",
        "outputId": "89ff77f5-a08a-4eb8-b884-b547ef76b3d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "/content/drive/MyDrive\n",
            "/content\n",
            "drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "%cd drive\n",
        "%cd MyDrive\n",
        "#%mkdir AITestKit\n",
        "%cd /content/\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rd9gxOuQ4BO4",
        "outputId": "c2dc03f4-5c3d-4585-f7ac-d899c05f05ad"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpX8ys0w4jUD",
        "outputId": "f47b574d-30ea-4c9f-ab57-fa7acb1923dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive'\n",
            "/content/drive\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iZy57hy42mv",
        "outputId": "d16ee1a2-b774-43fb-8f3d-531d2275d666"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'MyDrive'\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7npW0tI464N",
        "outputId": "48a9fe6b-a150-45c4-eef0-994ee3ce9c7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/AITestKit\n"
          ]
        }
      ],
      "source": [
        "%cd AITestKit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLfJ_T0D4qdx",
        "outputId": "238f6f2e-07ae-47d4-d325-acd98bd31e6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 399, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 399 (delta 0), reused 2 (delta 0), pack-reused 395\u001b[K\n",
            "Receiving objects: 100% (399/399), 4.43 MiB | 14.45 MiB/s, done.\n",
            "Resolving deltas: 100% (219/219), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mohamad-ali-nasser/gpt-2.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0KF2Ogb4xsH",
        "outputId": "663950ec-ddad-40fe-f84a-74427bf31605"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gpt-2\n",
            "Fetching checkpoint: 1.00kit [00:00, 805kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 4.53Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 542kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:27, 50.8Mit/s]                                 \n",
            "Fetching model.ckpt.index: 11.0kit [00:00, 7.49Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 927kit [00:00, 3.88Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 2.85Mit/s]                                                       \n"
          ]
        }
      ],
      "source": [
        "%cd gpt-2\n",
        "!python3 download_model.py 345M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ1fbAg75Ccw",
        "outputId": "4b11f503-7af8-4be6-9f63-90ab3f001a67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gpt-2/src\n",
            "/content/gpt-2/src/corpus\n"
          ]
        }
      ],
      "source": [
        "%cd src\n",
        "%mkdir corpus\n",
        "%cd corpus/\n",
        "!export PYTHONIOENCODING=UTF-8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqbnrPSJcYke"
      },
      "outputs": [],
      "source": [
        "# In Case I have saved checkpoints\n",
        "!cp -r /content/drive/MyDrive/AITestKit/gpt-2/checkpoint/run1/* /content/drive/MyDrive/AITestKit/gpt-2/models/345M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCDvFAYt6dDe"
      },
      "outputs": [],
      "source": [
        "!python3 /content/drive/MyDrive/AITestKit/gettext.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC2mEXn_8h8m",
        "outputId": "57d12c92-8325-4fa4-bb64-8cee9c925cff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-01-04 08:42:28--  https://www.gutenberg.org/files/98/98-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 807231 (788K) [text/plain]\n",
            "Saving to: ‘98-0.txt’\n",
            "\n",
            "98-0.txt            100%[===================>] 788.31K   695KB/s    in 1.1s    \n",
            "\n",
            "2023-01-04 08:42:30 (695 KB/s) - ‘98-0.txt’ saved [807231/807231]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.gutenberg.org/files/98/98-0.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1XBDpR8-Bdv"
      },
      "outputs": [],
      "source": [
        "!python3 /content/drive/MyDrive/AITestKit/jointext.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYZmna9V-M-l",
        "outputId": "6629a3fd-420e-4d3e-a77c-e8eb99453dc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/AITestKit/gpt-2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fire>=0.1.3\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting regex==2017.4.5\n",
            "  Downloading regex-2017.04.05.tar.gz (601 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.6/601.6 KB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting requests==2.21.0\n",
            "  Downloading requests-2.21.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.31.1\n",
            "  Downloading tqdm-4.31.1-py2.py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 KB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting toposort==1.5\n",
            "  Downloading toposort-1.5-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Collecting chardet<3.1.0,>=3.0.2\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 KB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2022.12.7)\n",
            "Collecting idna<2.9,>=2.5\n",
            "  Downloading idna-2.8-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (2.1.1)\n",
            "Building wheels for collected packages: regex, fire\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2017.4.5-cp38-cp38-linux_x86_64.whl size=553509 sha256=839d0b6234692a1d849237fa70f59d0350e53d7b6e24a4370b19c2200fa89d0f\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/6d/d9/1c9b861321c9240122cb967b734a80545c9f465be4fcb16f19\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116949 sha256=bbac46a66cb7d22e1268fd5a040ab8b4b72c0da13945f6ef4452212d230de05e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/eb/43/7295e71293b218ddfd627f935229bf54af9018add7fbb5aac6\n",
            "Successfully built regex fire\n",
            "Installing collected packages: toposort, regex, chardet, tqdm, idna, fire, requests\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2022.6.2\n",
            "    Uninstalling regex-2022.6.2:\n",
            "      Successfully uninstalled regex-2022.6.2\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 4.0.0\n",
            "    Uninstalling chardet-4.0.0:\n",
            "      Successfully uninstalled chardet-4.0.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.1\n",
            "    Uninstalling tqdm-4.64.1:\n",
            "      Successfully uninstalled tqdm-4.64.1\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Uninstalling requests-2.25.1:\n",
            "      Successfully uninstalled requests-2.25.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.4.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.31.1 which is incompatible.\n",
            "prophet 1.1.1 requires tqdm>=4.36.1, but you have tqdm 4.31.1 which is incompatible.\n",
            "panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.31.1 which is incompatible.\n",
            "nltk 3.7 requires regex>=2021.8.3, but you have regex 2017.4.5 which is incompatible.\n",
            "google-colab 1.0.0 requires requests>=2.25.1, but you have requests 2.21.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chardet-3.0.4 fire-0.5.0 idna-2.8 regex-2017.4.5 requests-2.21.0 toposort-1.5 tqdm-4.31.1\n"
          ]
        }
      ],
      "source": [
        "# Move into gpt-2 folder\n",
        "%cd /content/drive/MyDrive/AITestKit/gpt-2\n",
        "!pip3 install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG6P2Jc9BPZM",
        "outputId": "898c3ed7-4874-4c8c-9419-0dbf33d79476"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: tensorflow 2.9.2\n",
            "Uninstalling tensorflow-2.9.2:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.8/dist-packages/tensorflow-2.9.2.dist-info/*\n",
            "    /usr/local/lib/python3.8/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled tensorflow-2.9.2\n",
            " This PPA contains more recent Python versions packaged for Ubuntu.\n",
            "\n",
            "Disclaimer: there's no guarantee of timely updates in case of security problems or other issues. If you want to use them in a security-or-otherwise-critical environment (say, on a production server), you do so at your own risk.\n",
            "\n",
            "Update Note\n",
            "===========\n",
            "Please use this repository instead of ppa:fkrull/deadsnakes.\n",
            "\n",
            "Reporting Issues\n",
            "================\n",
            "\n",
            "Issues can be reported in the master issue tracker at:\n",
            "https://github.com/deadsnakes/issues/issues\n",
            "\n",
            "Supported Ubuntu and Python Versions\n",
            "====================================\n",
            "\n",
            "- Ubuntu 18.04 (bionic) Python2.3 - Python 2.6, Python 3.1 - Python 3.5, Python3.7 - Python3.11\n",
            "- Ubuntu 20.04 (focal) Python3.5 - Python3.7, Python3.9 - Python3.11\n",
            "- Ubuntu 22.04 (jammy) Python3.7 - Python3.9, Python3.11\n",
            "- Note: Python2.7 (all), Python 3.6 (bionic), Python 3.8 (focal), Python 3.10 (jammy) are not provided by deadsnakes as upstream ubuntu provides those packages.\n",
            "\n",
            "Why some packages aren't built:\n",
            "- Note: for focal, older python versions require libssl<1.1 so they are not currently built\n",
            "- Note: for jammy, older python versions requre libssl<3 so they are not currently built\n",
            "- If you need these, reach out to asottile to set up a private ppa\n",
            "\n",
            "The packages may also work on other versions of Ubuntu or Debian, but that is not tested or supported.\n",
            "\n",
            "Packages\n",
            "========\n",
            "\n",
            "The packages provided here are loosely based on the debian upstream packages with some modifications to make them more usable as non-default pythons and on ubuntu.  As such, the packages follow debian's patterns and often do not include a full python distribution with just `apt install python#.#`.  Here is a list of packages that may be useful along with the default install:\n",
            "\n",
            "- `python#.#-dev`: includes development headers for building C extensions\n",
            "- `python#.#-venv`: provides the standard library `venv` module\n",
            "- `python#.#-distutils`: provides the standard library `distutils` module\n",
            "- `python#.#-lib2to3`: provides the `2to3-#.#` utility as well as the standard library `lib2to3` module\n",
            "- `python#.#-gdbm`: provides the standard library `dbm.gnu` module\n",
            "- `python#.#-tk`: provides the standard library `tkinter` module\n",
            "\n",
            "Third-Party Python Modules\n",
            "==========================\n",
            "\n",
            "Python modules in the official Ubuntu repositories are packaged to work with the Python interpreters from the official repositories. Accordingly, they generally won't work with the Python interpreters from this PPA. As an exception, pure-Python modules for Python 3 will work, but any compiled extension modules won't.\n",
            "\n",
            "To install 3rd-party Python modules, you should use the common Python packaging tools.  For an introduction into the Python packaging ecosystem and its tools, refer to the Python Packaging User Guide:\n",
            "https://packaging.python.org/installing/\n",
            "\n",
            "Sources\n",
            "=======\n",
            "The package sources are available at:\n",
            "https://github.com/deadsnakes/\n",
            "\n",
            "Nightly Builds\n",
            "==============\n",
            "\n",
            "For nightly builds, see ppa:deadsnakes/nightly https://launchpad.net/~deadsnakes/+archive/ubuntu/nightly\n",
            " More info: https://launchpad.net/~deadsnakes/+archive/ubuntu/ppa\n",
            "Press [ENTER] to continue or Ctrl-c to cancel adding it.\n",
            "\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:2 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,568 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,344 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,237 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,100 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,525 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,144 kB]\n",
            "Fetched 14.2 MB in 5s (3,029 kB/s)\n",
            "Reading package lists... Done\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:10 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libpython3.7-minimal libpython3.7-stdlib python3.7-minimal\n",
            "Suggested packages:\n",
            "  python3.7-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.7-minimal libpython3.7-stdlib python3.7 python3.7-minimal\n",
            "0 upgraded, 4 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 4,448 kB of archives.\n",
            "After this operation, 22.5 MB of additional disk space will be used.\n",
            "Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.7-minimal amd64 3.7.16-1+bionic1 [589 kB]\n",
            "Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.7-minimal amd64 3.7.16-1+bionic1 [1,725 kB]\n",
            "Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.7-stdlib amd64 3.7.16-1+bionic1 [1,773 kB]\n",
            "Get:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.7 amd64 3.7.16-1+bionic1 [360 kB]\n",
            "Fetched 4,448 kB in 6s (802 kB/s)\n",
            "Selecting previously unselected package libpython3.7-minimal:amd64.\n",
            "(Reading database ... 124016 files and directories currently installed.)\n",
            "Preparing to unpack .../libpython3.7-minimal_3.7.16-1+bionic1_amd64.deb ...\n",
            "Unpacking libpython3.7-minimal:amd64 (3.7.16-1+bionic1) ...\n",
            "Selecting previously unselected package python3.7-minimal.\n",
            "Preparing to unpack .../python3.7-minimal_3.7.16-1+bionic1_amd64.deb ...\n",
            "Unpacking python3.7-minimal (3.7.16-1+bionic1) ...\n",
            "Selecting previously unselected package libpython3.7-stdlib:amd64.\n",
            "Preparing to unpack .../libpython3.7-stdlib_3.7.16-1+bionic1_amd64.deb ...\n",
            "Unpacking libpython3.7-stdlib:amd64 (3.7.16-1+bionic1) ...\n",
            "Selecting previously unselected package python3.7.\n",
            "Preparing to unpack .../python3.7_3.7.16-1+bionic1_amd64.deb ...\n",
            "Unpacking python3.7 (3.7.16-1+bionic1) ...\n",
            "Setting up libpython3.7-minimal:amd64 (3.7.16-1+bionic1) ...\n",
            "Setting up python3.7-minimal (3.7.16-1+bionic1) ...\n",
            "Setting up libpython3.7-stdlib:amd64 (3.7.16-1+bionic1) ...\n",
            "Setting up python3.7 (3.7.16-1+bionic1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libpython3.7 libpython3.7-dev\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.7 libpython3.7-dev python3.7-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 44.9 MB of archives.\n",
            "After this operation, 67.2 MB of additional disk space will be used.\n",
            "Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.7 amd64 3.7.16-1+bionic1 [1,527 kB]\n",
            "Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.7-dev amd64 3.7.16-1+bionic1 [42.9 MB]\n",
            "Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.7-dev amd64 3.7.16-1+bionic1 [501 kB]\n",
            "Fetched 44.9 MB in 8s (5,832 kB/s)\n",
            "Selecting previously unselected package libpython3.7:amd64.\n",
            "(Reading database ... 124632 files and directories currently installed.)\n",
            "Preparing to unpack .../libpython3.7_3.7.16-1+bionic1_amd64.deb ...\n",
            "Unpacking libpython3.7:amd64 (3.7.16-1+bionic1) ...\n",
            "Selecting previously unselected package libpython3.7-dev:amd64.\n",
            "Preparing to unpack .../libpython3.7-dev_3.7.16-1+bionic1_amd64.deb ...\n",
            "Unpacking libpython3.7-dev:amd64 (3.7.16-1+bionic1) ...\n",
            "Selecting previously unselected package python3.7-dev.\n",
            "Preparing to unpack .../python3.7-dev_3.7.16-1+bionic1_amd64.deb ...\n",
            "Unpacking python3.7-dev (3.7.16-1+bionic1) ...\n",
            "Setting up libpython3.7:amd64 (3.7.16-1+bionic1) ...\n",
            "Setting up libpython3.7-dev:amd64 (3.7.16-1+bionic1) ...\n",
            "Setting up python3.7-dev (3.7.16-1+bionic1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "--2023-01-04 13:09:04--  https://bootstrap.pypa.io/get-pip.py\n",
            "Resolving bootstrap.pypa.io (bootstrap.pypa.io)... 151.101.0.175, 151.101.64.175, 151.101.128.175, ...\n",
            "Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|151.101.0.175|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2569500 (2.5M) [text/x-python]\n",
            "Saving to: ‘get-pip.py.1’\n",
            "\n",
            "get-pip.py.1        100%[===================>]   2.45M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-01-04 13:09:04 (67.1 MB/s) - ‘get-pip.py.1’ saved [2569500/2569500]\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pip\n",
            "  Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools\n",
            "  Downloading setuptools-65.6.3-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wheel\n",
            "  Downloading wheel-0.38.4-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: wheel, setuptools, pip\n",
            "Successfully installed pip-22.3.1 setuptools-65.6.3 wheel-0.38.4\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!yes|pip uninstall tensorflow\n",
        "\n",
        "!add-apt-repository ppa:deadsnakes/ppa\n",
        "!apt-get update\n",
        "!apt-get install python3.7\n",
        "!apt-get install python3.7-dev\n",
        "\n",
        "!wget https://bootstrap.pypa.io/get-pip.py && python3.7 get-pip.py\n",
        "\n",
        "import sys\n",
        "\n",
        "sys.path[2] = '/usr/lib/python37.zip'\n",
        "sys.path[3] = '/usr/lib/python3.7'\n",
        "sys.path[4] = '/usr/lib/python3.7/lib-dynload'\n",
        "sys.path[5] = '/usr/local/lib/python3.7/dist-packages'\n",
        "sys.path[7] ='/usr/local/lib/python3.7/dist-packages/IPython/extensions'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AmSwb1Xj-TK4",
        "outputId": "cb9168e0-43c9-41e3-e4d9-1a6a999d2e52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu==1.15.0\n",
            "  Downloading tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (411.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.5/411.5 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting astor>=0.6.0\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.4/503.4 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio>=1.8.6\n",
            "  Downloading grpcio-1.51.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting six>=1.10.0\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting protobuf>=3.6.1\n",
            "  Downloading protobuf-4.21.12-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.8/409.8 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (0.38.4)\n",
            "Collecting keras-preprocessing>=1.0.5\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy<2.0,>=1.16.0\n",
            "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-pasta>=0.1.6\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wrapt>=1.11.1\n",
            "  Downloading wrapt-1.14.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.2/75.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting termcolor>=1.1.0\n",
            "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
            "Collecting absl-py>=0.7.0\n",
            "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h5py\n",
            "  Downloading h5py-3.7.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting werkzeug>=0.11.15\n",
            "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.7/232.7 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (65.6.3)\n",
            "Collecting importlib-metadata>=4.4\n",
            "  Downloading importlib_metadata-6.0.0-py3-none-any.whl (21 kB)\n",
            "Collecting MarkupSafe>=2.1.1\n",
            "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting typing-extensions>=3.6.4\n",
            "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.11.0-py3-none-any.whl (6.6 kB)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7537 sha256=7a178a3bf5cb46204ea40982182317ae71a7bc2f63bcb6ce35f2d03591f569d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/87/6f/3f34218ef184368cec9ee65bdfd65baf117811f0a0ce1263ff\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, zipp, wrapt, typing-extensions, termcolor, six, protobuf, numpy, MarkupSafe, grpcio, gast, astor, absl-py, werkzeug, opt-einsum, keras-preprocessing, importlib-metadata, h5py, google-pasta, markdown, keras-applications, tensorboard, tensorflow-gpu\n",
            "Successfully installed MarkupSafe-2.1.1 absl-py-1.3.0 astor-0.8.1 gast-0.2.2 google-pasta-0.2.0 grpcio-1.51.1 h5py-3.7.0 importlib-metadata-6.0.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.4.1 numpy-1.21.6 opt-einsum-3.3.0 protobuf-4.21.12 six-1.16.0 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0 termcolor-2.2.0 typing-extensions-4.4.0 werkzeug-2.2.2 wrapt-1.14.1 zipp-3.11.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "astor",
                  "grpc",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.5/488.5 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow-estimator\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-gpu 1.15.0 requires tensorflow-estimator==1.15.1, but you have tensorflow-estimator 1.14.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tensorflow-estimator-1.14.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-gpu==1.15.0\n",
        "#!pip install https://us-python.pkg.dev/colab-wheels/public/simple/\n",
        "!pip install 'tensorflow-estimator<1.15.0rc0,>=1.14.0rc0' --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZnRce7ZpoK7",
        "outputId": "c55fa309-9be3-4daf-8654-18d454dd0e1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Using cached tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "Installing collected packages: tensorflow-estimator\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 1.14.0\n",
            "    Uninstalling tensorflow-estimator-1.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-1.14.0\n",
            "Successfully installed tensorflow-estimator-1.15.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-estimator==1.15.1 --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfTAsJtRft4N",
        "outputId": "64a2f9dd-9b6f-4ac5-c425-ebb76187fbf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package cuda-repo-ubuntu1604-9-0-local.\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 124788 files and directories currently installed.)\n",
            "Preparing to unpack cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb ...\n",
            "Unpacking cuda-repo-ubuntu1604-9-0-local (9.0.176-1) ...\n",
            "Setting up cuda-repo-ubuntu1604-9-0-local (9.0.176-1) ...\n",
            "OK\n",
            "Get:1 file:/var/cuda-repo-9-0-local  InRelease\n",
            "Ign:1 file:/var/cuda-repo-9-0-local  InRelease\n",
            "Get:2 file:/var/cuda-repo-9-0-local  Release [574 B]\n",
            "Get:2 file:/var/cuda-repo-9-0-local  Release [574 B]\n",
            "Get:3 file:/var/cuda-repo-9-0-local  Release.gpg [819 B]\n",
            "Get:3 file:/var/cuda-repo-9-0-local  Release.gpg [819 B]\n",
            "Hit:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Get:5 file:/var/cuda-repo-9-0-local  Packages [15.4 kB]\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:14 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:17 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  cuda-command-line-tools-9-0 cuda-core-9-0 cuda-cublas-9-0\n",
            "  cuda-cublas-dev-9-0 cuda-cudart-9-0 cuda-cudart-dev-9-0 cuda-cufft-9-0\n",
            "  cuda-cufft-dev-9-0 cuda-curand-9-0 cuda-curand-dev-9-0 cuda-cusolver-9-0\n",
            "  cuda-cusolver-dev-9-0 cuda-cusparse-9-0 cuda-cusparse-dev-9-0\n",
            "  cuda-demo-suite-9-0 cuda-documentation-9-0 cuda-driver-dev-9-0\n",
            "  cuda-libraries-9-0 cuda-libraries-dev-9-0 cuda-license-9-0\n",
            "  cuda-misc-headers-9-0 cuda-npp-9-0 cuda-npp-dev-9-0 cuda-nvgraph-9-0\n",
            "  cuda-nvgraph-dev-9-0 cuda-nvml-dev-9-0 cuda-nvrtc-9-0 cuda-nvrtc-dev-9-0\n",
            "  cuda-runtime-9-0 cuda-samples-9-0 cuda-toolkit-9-0 cuda-visual-tools-9-0\n",
            "  freeglut3 freeglut3-dev libxi-dev libxmu-dev libxmu-headers\n",
            "  x11proto-input-dev\n",
            "The following NEW packages will be installed:\n",
            "  cuda-9-0 cuda-command-line-tools-9-0 cuda-core-9-0 cuda-cublas-9-0\n",
            "  cuda-cublas-dev-9-0 cuda-cudart-9-0 cuda-cudart-dev-9-0 cuda-cufft-9-0\n",
            "  cuda-cufft-dev-9-0 cuda-curand-9-0 cuda-curand-dev-9-0 cuda-cusolver-9-0\n",
            "  cuda-cusolver-dev-9-0 cuda-cusparse-9-0 cuda-cusparse-dev-9-0\n",
            "  cuda-demo-suite-9-0 cuda-documentation-9-0 cuda-driver-dev-9-0\n",
            "  cuda-libraries-9-0 cuda-libraries-dev-9-0 cuda-license-9-0\n",
            "  cuda-misc-headers-9-0 cuda-npp-9-0 cuda-npp-dev-9-0 cuda-nvgraph-9-0\n",
            "  cuda-nvgraph-dev-9-0 cuda-nvml-dev-9-0 cuda-nvrtc-9-0 cuda-nvrtc-dev-9-0\n",
            "  cuda-runtime-9-0 cuda-samples-9-0 cuda-toolkit-9-0 cuda-visual-tools-9-0\n",
            "  freeglut3 freeglut3-dev libxi-dev libxmu-dev libxmu-headers\n",
            "  x11proto-input-dev\n",
            "0 upgraded, 39 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 489 kB/1,097 MB of archives.\n",
            "After this operation, 2,317 MB of additional disk space will be used.\n",
            "Get:1 file:/var/cuda-repo-9-0-local  cuda-license-9-0 9.0.176-1 [22.0 kB]\n",
            "Get:2 file:/var/cuda-repo-9-0-local  cuda-misc-headers-9-0 9.0.176-1 [684 kB]\n",
            "Get:3 file:/var/cuda-repo-9-0-local  cuda-core-9-0 9.0.176-1 [16.9 MB]\n",
            "Get:4 file:/var/cuda-repo-9-0-local  cuda-cudart-9-0 9.0.176-1 [106 kB]\n",
            "Get:5 file:/var/cuda-repo-9-0-local  cuda-driver-dev-9-0 9.0.176-1 [10.9 kB]\n",
            "Get:6 file:/var/cuda-repo-9-0-local  cuda-cudart-dev-9-0 9.0.176-1 [767 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 freeglut3 amd64 2.8.1-3 [73.6 kB]\n",
            "Get:8 file:/var/cuda-repo-9-0-local  cuda-command-line-tools-9-0 9.0.176-1 [25.4 MB]\n",
            "Get:9 file:/var/cuda-repo-9-0-local  cuda-nvrtc-9-0 9.0.176-1 [6,348 kB]\n",
            "Get:10 file:/var/cuda-repo-9-0-local  cuda-nvrtc-dev-9-0 9.0.176-1 [9,334 B]\n",
            "Get:11 file:/var/cuda-repo-9-0-local  cuda-cusolver-9-0 9.0.176-1 [26.2 MB]\n",
            "Get:12 file:/var/cuda-repo-9-0-local  cuda-cusolver-dev-9-0 9.0.176-1 [5,317 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/universe amd64 freeglut3-dev amd64 2.8.1-3 [124 kB]\n",
            "Get:14 file:/var/cuda-repo-9-0-local  cuda-cublas-9-0 9.0.176-1 [25.0 MB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxmu-headers all 2:1.1.2-2 [54.3 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxmu-dev amd64 2:1.1.2-2 [49.0 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-input-dev all 2018.4-4 [2,620 B]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxi-dev amd64 2:1.7.9-1 [186 kB]\n",
            "Get:19 file:/var/cuda-repo-9-0-local  cuda-cublas-dev-9-0 9.0.176-1 [49.4 MB]\n",
            "Get:20 file:/var/cuda-repo-9-0-local  cuda-cufft-9-0 9.0.176-1 [84.1 MB]\n",
            "Get:21 file:/var/cuda-repo-9-0-local  cuda-cufft-dev-9-0 9.0.176-1 [73.7 MB]\n",
            "Get:22 file:/var/cuda-repo-9-0-local  cuda-curand-9-0 9.0.176-1 [38.8 MB]\n",
            "Get:23 file:/var/cuda-repo-9-0-local  cuda-curand-dev-9-0 9.0.176-1 [57.9 MB]\n",
            "Get:24 file:/var/cuda-repo-9-0-local  cuda-cusparse-9-0 9.0.176-1 [25.2 MB]\n",
            "Get:25 file:/var/cuda-repo-9-0-local  cuda-cusparse-dev-9-0 9.0.176-1 [25.3 MB]\n",
            "Get:26 file:/var/cuda-repo-9-0-local  cuda-npp-9-0 9.0.176-1 [46.6 MB]\n",
            "Get:27 file:/var/cuda-repo-9-0-local  cuda-npp-dev-9-0 9.0.176-1 [46.6 MB]\n",
            "Get:28 file:/var/cuda-repo-9-0-local  cuda-nvgraph-9-0 9.0.176-1 [6,081 kB]\n",
            "Get:29 file:/var/cuda-repo-9-0-local  cuda-nvgraph-dev-9-0 9.0.176-1 [5,658 kB]\n",
            "Get:30 file:/var/cuda-repo-9-0-local  cuda-samples-9-0 9.0.176-1 [75.9 MB]\n",
            "Get:31 file:/var/cuda-repo-9-0-local  cuda-documentation-9-0 9.0.176-1 [53.1 MB]\n",
            "Get:32 file:/var/cuda-repo-9-0-local  cuda-libraries-dev-9-0 9.0.176-1 [2,596 B]\n",
            "Get:33 file:/var/cuda-repo-9-0-local  cuda-nvml-dev-9-0 9.0.176-1 [47.6 kB]\n",
            "Get:34 file:/var/cuda-repo-9-0-local  cuda-visual-tools-9-0 9.0.176-1 [398 MB]\n",
            "Get:35 file:/var/cuda-repo-9-0-local  cuda-toolkit-9-0 9.0.176-1 [2,836 B]\n",
            "Get:36 file:/var/cuda-repo-9-0-local  cuda-libraries-9-0 9.0.176-1 [2,566 B]\n",
            "Get:37 file:/var/cuda-repo-9-0-local  cuda-runtime-9-0 9.0.176-1 [2,526 B]\n",
            "Get:38 file:/var/cuda-repo-9-0-local  cuda-demo-suite-9-0 9.0.176-1 [3,880 kB]\n",
            "Get:39 file:/var/cuda-repo-9-0-local  cuda-9-0 9.0.176-1 [2,552 B]\n",
            "Fetched 489 kB in 15s (33.4 kB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package cuda-license-9-0.\n",
            "(Reading database ... 124847 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cuda-license-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-license-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-misc-headers-9-0.\n",
            "Preparing to unpack .../01-cuda-misc-headers-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-misc-headers-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-core-9-0.\n",
            "Preparing to unpack .../02-cuda-core-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-core-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cudart-9-0.\n",
            "Preparing to unpack .../03-cuda-cudart-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cudart-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-driver-dev-9-0.\n",
            "Preparing to unpack .../04-cuda-driver-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-driver-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cudart-dev-9-0.\n",
            "Preparing to unpack .../05-cuda-cudart-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cudart-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-command-line-tools-9-0.\n",
            "Preparing to unpack .../06-cuda-command-line-tools-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-command-line-tools-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "Preparing to unpack .../07-freeglut3_2.8.1-3_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-3) ...\n",
            "Selecting previously unselected package freeglut3-dev:amd64.\n",
            "Preparing to unpack .../08-freeglut3-dev_2.8.1-3_amd64.deb ...\n",
            "Unpacking freeglut3-dev:amd64 (2.8.1-3) ...\n",
            "Selecting previously unselected package libxmu-headers.\n",
            "Preparing to unpack .../09-libxmu-headers_2%3a1.1.2-2_all.deb ...\n",
            "Unpacking libxmu-headers (2:1.1.2-2) ...\n",
            "Selecting previously unselected package libxmu-dev:amd64.\n",
            "Preparing to unpack .../10-libxmu-dev_2%3a1.1.2-2_amd64.deb ...\n",
            "Unpacking libxmu-dev:amd64 (2:1.1.2-2) ...\n",
            "Selecting previously unselected package x11proto-input-dev.\n",
            "Preparing to unpack .../11-x11proto-input-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-input-dev (2018.4-4) ...\n",
            "Selecting previously unselected package libxi-dev:amd64.\n",
            "Preparing to unpack .../12-libxi-dev_2%3a1.7.9-1_amd64.deb ...\n",
            "Unpacking libxi-dev:amd64 (2:1.7.9-1) ...\n",
            "Selecting previously unselected package cuda-nvrtc-9-0.\n",
            "Preparing to unpack .../13-cuda-nvrtc-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-nvrtc-dev-9-0.\n",
            "Preparing to unpack .../14-cuda-nvrtc-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cusolver-9-0.\n",
            "Preparing to unpack .../15-cuda-cusolver-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cusolver-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cusolver-dev-9-0.\n",
            "Preparing to unpack .../16-cuda-cusolver-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cusolver-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cublas-9-0.\n",
            "Preparing to unpack .../17-cuda-cublas-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cublas-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cublas-dev-9-0.\n",
            "Preparing to unpack .../18-cuda-cublas-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cublas-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cufft-9-0.\n",
            "Preparing to unpack .../19-cuda-cufft-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cufft-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cufft-dev-9-0.\n",
            "Preparing to unpack .../20-cuda-cufft-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cufft-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-curand-9-0.\n",
            "Preparing to unpack .../21-cuda-curand-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-curand-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-curand-dev-9-0.\n",
            "Preparing to unpack .../22-cuda-curand-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-curand-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cusparse-9-0.\n",
            "Preparing to unpack .../23-cuda-cusparse-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cusparse-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cusparse-dev-9-0.\n",
            "Preparing to unpack .../24-cuda-cusparse-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cusparse-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-npp-9-0.\n",
            "Preparing to unpack .../25-cuda-npp-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-npp-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-npp-dev-9-0.\n",
            "Preparing to unpack .../26-cuda-npp-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-npp-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-nvgraph-9-0.\n",
            "Preparing to unpack .../27-cuda-nvgraph-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-nvgraph-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-nvgraph-dev-9-0.\n",
            "Preparing to unpack .../28-cuda-nvgraph-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-nvgraph-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-samples-9-0.\n",
            "Preparing to unpack .../29-cuda-samples-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-samples-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-documentation-9-0.\n",
            "Preparing to unpack .../30-cuda-documentation-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-documentation-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-libraries-dev-9-0.\n",
            "Preparing to unpack .../31-cuda-libraries-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-libraries-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-nvml-dev-9-0.\n",
            "Preparing to unpack .../32-cuda-nvml-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-nvml-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-visual-tools-9-0.\n",
            "Preparing to unpack .../33-cuda-visual-tools-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-visual-tools-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-toolkit-9-0.\n",
            "Preparing to unpack .../34-cuda-toolkit-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-toolkit-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-libraries-9-0.\n",
            "Preparing to unpack .../35-cuda-libraries-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-libraries-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-runtime-9-0.\n",
            "Preparing to unpack .../36-cuda-runtime-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-runtime-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-demo-suite-9-0.\n",
            "Preparing to unpack .../37-cuda-demo-suite-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-demo-suite-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-9-0.\n",
            "Preparing to unpack .../38-cuda-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-9-0 (9.0.176-1) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-3) ...\n",
            "Setting up libxmu-headers (2:1.1.2-2) ...\n",
            "Setting up cuda-license-9-0 (9.0.176-1) ...\n",
            "*** LICENSE AGREEMENT ***\n",
            "By using this software you agree to fully comply with the terms and \n",
            "conditions of the EULA (End User License Agreement). The EULA is located\n",
            "at /usr/local/cuda-9.0/doc/EULA.txt. The EULA can also be found at\n",
            "http://docs.nvidia.com/cuda/eula/index.html. If you do not agree to the\n",
            "terms and conditions of the EULA, do not use the software.\n",
            "\n",
            "Setting up freeglut3-dev:amd64 (2.8.1-3) ...\n",
            "Setting up x11proto-input-dev (2018.4-4) ...\n",
            "Setting up cuda-cusparse-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cudart-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-nvrtc-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cusparse-dev-9-0 (9.0.176-1) ...\n",
            "Setting up libxmu-dev:amd64 (2:1.1.2-2) ...\n",
            "Setting up cuda-cufft-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cusolver-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-nvml-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-npp-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cusolver-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-misc-headers-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cublas-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-nvrtc-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-driver-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-curand-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-nvgraph-9-0 (9.0.176-1) ...\n",
            "Setting up libxi-dev:amd64 (2:1.7.9-1) ...\n",
            "Setting up cuda-core-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-libraries-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-runtime-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cudart-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cufft-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-npp-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-curand-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cublas-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-nvgraph-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-command-line-tools-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-demo-suite-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-visual-tools-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-samples-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-libraries-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-documentation-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-toolkit-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-9-0 (9.0.176-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n"
          ]
        }
      ],
      "source": [
        "%cp /content/drive/MyDrive/ColabNotebooks/PBHU-ST/gpt-2/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb \n",
        "!dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
        "!apt-key add /var/cuda-repo-*/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda-9-0\n",
        "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-9.0/lib64/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Uk90Y6WYhTaa",
        "outputId": "3cefc90b-12b2-4fc4-8aab-f0dd1340eecc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4X9O1r57guIL"
      },
      "outputs": [],
      "source": [
        "%cd gpt-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3cYEcWV-ctP"
      },
      "outputs": [],
      "source": [
        "#!wget https://developer.nvidia.com/compute/cuda/9.2/Prod2/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.148-1_amd64\n",
        "#!apt list --installed\n",
        "#!apt-get install dpkg\n",
        "#!apt remove cuda* libcu* libnpp-12* libnvjitlink-12* libjpeg-12*\n",
        "!apt full-upgrade\n",
        "!apt-get install --reinstall dpkg\n",
        "#!apt --fix-missing\n",
        "!apt --fix-broken install\n",
        "!apt autoremove\n",
        "#!dpkg -configure -a\n",
        "#!apt-get install -f\n",
        "# !apt-get install --reinstall dpkg\n",
        "# !dpkg -i /content/drive/MyDrive/ColabNotebooks/PBHU-ST/_share_aiPhilosopher/_aiPhilosopher_program_file/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
        "# !apt-key add /var/cuda-repo-9-0/7fa2af80.pub\n",
        "# !apt-get update\n",
        "# !apt-get install cuda-9-0\n",
        "# !export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-9.0/lib64/\n",
        "#!wget https://developer.nvidia.com/downloads/compute/cuda/9.0/Prod/local_installers/cuda_9.0.176_384.81_linux-run\n",
        "#!sh cuda_9.0.176_384.81_linux.run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhVyiMFqNYTi"
      },
      "outputs": [],
      "source": [
        "!apt --fix-broken install\n",
        "!dpkg --configure -a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeX0R8wUQfon"
      },
      "outputs": [],
      "source": [
        "!apt autoremove\n",
        "!apt update\n",
        "!apt upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QTJcNBpFoxM"
      },
      "outputs": [],
      "source": [
        "!apt-key add /var/cuda*/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda-9-0\n",
        "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-9.0/lib64/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1hrgeKFYsuE"
      },
      "source": [
        "Download the model data - we will only consider pre-trained models that are small and medium in size (due to time, space)\n",
        "\n",
        "*   117M\n",
        "*   345M\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A498TySgHYyF",
        "outputId": "437baaef-5bc4-4fe2-e7d2-2e5419644df3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.00kit [00:00, 632kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 4.01Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 626kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:12, 41.4Mit/s]                                  \n",
            "Fetching model.ckpt.index: 6.00kit [00:00, 3.12Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 472kit [00:00, 3.01Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 2.87Mit/s]                                                       \n"
          ]
        }
      ],
      "source": [
        "!python3 download_model.py 117M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UDpEGjfO8Q2",
        "outputId": "61a4fe9d-c3b7-405e-b544-965278553b7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.00kit [00:00, 882kit/s]                                                      \n",
            "Fetching encoder.json: 1.00kit [00:00, 883kit/s]                                                    \n",
            "Fetching hparams.json: 1.00kit [00:00, 840kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.00kit [00:00, 891kit/s]                                  \n",
            "Fetching model.ckpt.index: 1.00kit [00:00, 887kit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.00kit [00:00, 876kit/s]                                                 \n",
            "Fetching vocab.bpe: 1.00kit [00:00, 932kit/s]                                                       \n"
          ]
        }
      ],
      "source": [
        "!python3 download_model.py 345M"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq-YwRnNOBYO"
      },
      "source": [
        "encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oJPQtdLbbeK"
      },
      "outputs": [],
      "source": [
        "!export PYTHONIOENCODING=UTF-8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KzSbAvePgsI"
      },
      "source": [
        "Fetch checkpoints if you have them saved in google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cA2Wk7yIPmS6"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/ColabNotebooks/checkpoint/ /content/GPT2_example_CAMEROON/ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p--9zwqQRTc"
      },
      "source": [
        "\n",
        "Let's get our train on! In this case the file is A Tale of Two Cities (Charles Dickens) from Project Gutenberg. To change the dataset GPT-2 models will fine-tune on, change this URL to another .txt file, and change corresponding part of the next cell. Note that you can use small datasets if you want but you will have to be sure not to run the fine-tuning for too long or you will overfit badly. Roughly, expect interesting results within minutes to hours in the 1-10s of megabyte ballpark, and below this you may want to stop the run early as fine-tuning can be very fast."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOCvrs-DHvxa",
        "outputId": "5f1a4edb-b4b8-400b-8042-edbf8c56fa03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-01-04 06:07:40--  https://www.gutenberg.org/files/98/98-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 807231 (788K) [text/plain]\n",
            "Saving to: ‘98-0.txt.1’\n",
            "\n",
            "98-0.txt.1          100%[===================>] 788.31K   692KB/s    in 1.1s    \n",
            "\n",
            "2023-01-04 06:07:42 (692 KB/s) - ‘98-0.txt.1’ saved [807231/807231]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.gutenberg.org/files/98/98-0.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPfJ5b3CQXqr"
      },
      "source": [
        "\n",
        "Start training, add --model_name '345M' to use 345 model. Use 117M for the smaller model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Gdy9nfFinXYJ",
        "outputId": "48e07084-fbe9-403b-ddc6-8ed769663f8e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVW5cdKAsNVM",
        "outputId": "1cb8531c-4695-42d8-cadc-761c3aa3ed79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/AITestKit/gpt-2\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/AITestKit/gpt-2/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "id": "pEn_ihcGI00T",
        "outputId": "5840312e-3f78-4843-9813-121b09708c97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting protobuf==3.20.1\n",
            "  Downloading protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.21.12\n",
            "    Uninstalling protobuf-4.21.12:\n",
            "      Successfully uninstalled protobuf-4.21.12\n",
            "Successfully installed protobuf-3.20.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fire>=0.1.3\n",
            "  Using cached fire-0.5.0.tar.gz (88 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting regex==2017.4.5\n",
            "  Using cached regex-2017.04.05.tar.gz (601 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting requests==2.21.0\n",
            "  Using cached requests-2.21.0-py2.py3-none-any.whl (57 kB)\n",
            "Collecting tqdm==4.31.1\n",
            "  Using cached tqdm-4.31.1-py2.py3-none-any.whl (48 kB)\n",
            "Collecting toposort==1.5\n",
            "  Using cached toposort-1.5-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting chardet<3.1.0,>=3.0.2\n",
            "  Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "Collecting certifi>=2017.4.17\n",
            "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna<2.9,>=2.5\n",
            "  Using cached idna-2.8-py2.py3-none-any.whl (58 kB)\n",
            "Collecting urllib3<1.25,>=1.21.1\n",
            "  Downloading urllib3-1.24.3-py2.py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.8/118.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (2.2.0)\n",
            "Building wheels for collected packages: regex, fire\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2017.4.5-cp37-cp37m-linux_x86_64.whl size=534425 sha256=dad9c04cb3f342333f0bef4e4b6e20265749a9006276a58d4a2d733b9bf3d466\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/65/b8/dc33f60f985dd67bb63dea6acbafd9581be485a3308bf32a3b\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116931 sha256=0a3ccdf23a0fedf80db233a5230f4b638280f07898d645451d04d46c26e673c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/e8/7b/003fc14f02f262dd4614aec55e41147c8012e3dad98c936b76\n",
            "Successfully built regex fire\n",
            "Installing collected packages: toposort, regex, chardet, urllib3, tqdm, idna, fire, certifi, requests\n",
            "Successfully installed certifi-2022.12.7 chardet-3.0.4 fire-0.5.0 idna-2.8 regex-2017.4.5 requests-2.21.0 toposort-1.5 tqdm-4.31.1 urllib3-1.24.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install protobuf==3.20.1\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkLp2-VfsleZ",
        "outputId": "70a47394-e5e7-4e1a-ec72-dd8fbf27c107"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/memory_saving_gradients.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:88: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:91: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2023-01-04 13:20:38.267148: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2023-01-04 13:20:38.272897: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2023-01-04 13:20:38.273257: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1767c00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2023-01-04 13:20:38.273292: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2023-01-04 13:20:38.276350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2023-01-04 13:20:39.116366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-01-04 13:20:39.117083: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1768840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2023-01-04 13:20:39.117116: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2023-01-04 13:20:39.117952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-01-04 13:20:39.118504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2023-01-04 13:20:39.118701: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:20:39.118819: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:20:39.118913: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:20:39.119016: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:20:39.119108: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:20:39.119209: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:20:39.119324: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:20:39.119340: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2023-01-04 13:20:39.119381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2023-01-04 13:20:39.119393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2023-01-04 13:20:39.119402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "WARNING:tensorflow:From ./train.py:92: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/model.py:166: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/sample.py:65: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/sample.py:70: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From ./train.py:117: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:121: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/memory_saving_gradients.py:62: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n",
            "Instructions for updating:\n",
            "Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/memory_saving_gradients.py:89: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:144: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:147: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:149: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:152: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:156: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "2023-01-04 13:21:12.654293: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 205852672 exceeds 10% of system memory.\n",
            "Loading checkpoint checkpoint/run1/model-7\n",
            "2023-01-04 13:21:13.850293: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 205852672 exceeds 10% of system memory.\n",
            "Loading dataset...\n",
            "100% 1/1 [00:01<00:00,  1.85s/it]\n",
            "dataset has 233500 tokens\n",
            "Training...\n",
            "2023-01-04 13:21:36.263289: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 205852672 exceeds 10% of system memory.\n",
            "2023-01-04 13:21:37.357925: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 205651644 exceeds 10% of system memory.\n",
            "2023-01-04 13:21:43.444496: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 205852672 exceeds 10% of system memory.\n",
            "[8 | 50.85] loss=3.22 avg=3.22\n",
            "[9 | 90.88] loss=2.80 avg=3.01\n",
            "[10 | 129.17] loss=2.67 avg=2.90\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!chmod u+rwx train.py\n",
        "#!export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python #makes very slow but a fix\n",
        "!PYTHONPATH=src ./train.py --dataset src/corpus/corpus.txt --model_name '345M'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYxJHcD1thc3",
        "outputId": "8f5b5378-e42d-40cc-f8c7-fade62638c2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/memory_saving_gradients.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:88: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:91: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2023-01-04 13:23:53.334979: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2023-01-04 13:23:53.339496: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2023-01-04 13:23:53.339780: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x21f5c00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2023-01-04 13:23:53.339816: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2023-01-04 13:23:53.341510: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2023-01-04 13:23:54.133427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-01-04 13:23:54.134181: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x21f6840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2023-01-04 13:23:54.134231: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2023-01-04 13:23:54.134398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-01-04 13:23:54.134946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2023-01-04 13:23:54.135075: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:23:54.135161: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:23:54.135249: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:23:54.135323: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:23:54.135397: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:23:54.135474: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:23:54.135547: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:23:54.135565: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2023-01-04 13:23:54.135592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2023-01-04 13:23:54.135607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2023-01-04 13:23:54.135620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "WARNING:tensorflow:From ./train.py:92: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/model.py:166: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/sample.py:65: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/sample.py:70: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From ./train.py:117: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:121: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/memory_saving_gradients.py:62: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n",
            "Instructions for updating:\n",
            "Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/memory_saving_gradients.py:89: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:144: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:147: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:149: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:152: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:156: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "Loading checkpoint checkpoint/run1/model-7\n",
            "Loading dataset...\n",
            "100% 1/1 [00:01<00:00,  1.10s/it]\n",
            "dataset has 233500 tokens\n",
            "Training...\n",
            "2023-01-04 13:24:37.793301: E tensorflow/core/framework/types.cc:104] Unrecognized DataType enum value 2046940888\n",
            "[8 | 49.61] loss=2.52 avg=2.52\n",
            "[9 | 88.99] loss=2.44 avg=2.48\n",
            "[10 | 126.56] loss=3.00 avg=2.65\n",
            "[11 | 163.94] loss=2.59 avg=2.64\n",
            "[12 | 201.14] loss=3.37 avg=2.79\n",
            "[13 | 239.30] loss=3.31 avg=2.88\n",
            "[14 | 278.66] loss=3.36 avg=2.95\n",
            "interrupted\n",
            "Saving checkpoint/run1/model-15\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=src ./train.py --dataset src/corpus/corpus.txt --model_name '345M' --batch_size 1 --learning_rate 0.00001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TqvccvXKv9Co",
        "outputId": "31cda17d-6ece-447c-b227-afa6ab65d768"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/AITestKit/gpt-2'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS1RJJDFOPnb"
      },
      "source": [
        "Save our checkpoints to start training again later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JretqG1zOXdi"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/AITestKit/gpt-2/checkpoint /content/drive/MyDrive/AITestKit/checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D-i7vERWbNS"
      },
      "source": [
        "Load your trained model for use in sampling below (117M or 345M)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeETvWvrbKga"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/AITestKit/gpt-2/checkpoint/run1/* /content/drive/MyDrive/AITestKit/gpt-2/models/117M/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "np0r6qfXBeUX"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/AITestKit/gpt-2/checkpoint/run1/* /content/drive/MyDrive/AITestKit/gpt-2/models/345M/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmnSrXqtfRbq"
      },
      "source": [
        "# Have fun with the model inputs! Try words, sentences, paragraphs!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mkEyaS_yEr0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "%cd src\n",
        "from conditional_model import conditional_model\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Qc5lUSqyKaR",
        "outputId": "920d279f-e715-49a9-99cd-c85ed94b638b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/AITestKit/gpt-2/src\n"
          ]
        }
      ],
      "source": [
        "%cd src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65n4EA0cwqq3",
        "outputId": "0e37851c-4ca4-4698-d82b-98b406e8118a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/AITestKit/gpt-2\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2trGt4sm2jHf"
      },
      "source": [
        "Generate conditional samples from the model given a prompt you provide -  change top-k hyperparameter if desired (default is 40),  if you're using 345M, add \"--model-name 345M\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utJj-iY4gHwE",
        "outputId": "55871193-7809-49b7-a842-1ba1c0688f4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:55: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2023-01-04 13:31:14.490362: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2023-01-04 13:31:15.133489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-01-04 13:31:15.134140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2023-01-04 13:31:15.134375: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:31:15.134556: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:31:15.134707: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:31:15.134822: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:31:15.134914: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:31:15.135008: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:31:15.135098: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:31:15.135112: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2023-01-04 13:31:15.139175: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2023-01-04 13:31:15.143933: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2023-01-04 13:31:15.144221: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x31c4140 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2023-01-04 13:31:15.144256: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2023-01-04 13:31:15.338816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-01-04 13:31:15.339961: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x31c4840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2023-01-04 13:31:15.340001: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2023-01-04 13:31:15.340141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2023-01-04 13:31:15.340161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      \n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:56: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:58: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/model.py:166: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/sample.py:65: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/sample.py:70: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:66: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "2023-01-04 13:31:22.689992: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 205852672 exceeds 10% of system memory.\n",
            "Model prompt >>> Hello how are you today?\n",
            "2023-01-04 13:32:56.836896: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 95944704 exceeds 10% of system memory.\n",
            "2023-01-04 13:32:57.003977: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 96141312 exceeds 10% of system memory.\n",
            "2023-01-04 13:32:57.180159: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 96337920 exceeds 10% of system memory.\n",
            "2023-01-04 13:32:57.357029: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 96534528 exceeds 10% of system memory.\n",
            "======================================== SAMPLE 1 ========================================\n",
            " You still up late? Why are you still up in bed?\"\n",
            "\n",
            "I looked so tired, but in my mind's eye I heard my parents say, \"Go to the kitchen and get ready, Dad, we don't know what a nightmare you're going through. We want you to put a pillow inside your bed and forget about it, alright?\"\n",
            "\n",
            "My mom said those last words with such a heavy burden on her voice. I was so tired, I almost fell asleep.\n",
            "\n",
            "When I realized why they were saying that, I was glad I said it earlier; I wish I had never heard them.\n",
            "\n",
            "I was so sorry I didn't call them back, my head was buzzing from sleep. I had gone through so many things in the past few days. It's so easy to get distracted. I didn't even know why I put up with the pain.\n",
            "\n",
            "It was all those things, and a big part of it was me, and my mind, and my heart. It's so easy for me to get into situations that can be dangerous, and I'm used to them, with a bunch of old memories with a lot of blood on them.\n",
            "\n",
            "But I'm sorry I'm trying to get out of these little ruts of sleep. I want to start working to get back in shape, and then I will get back to where I was.\n",
            "\n",
            "So I go to get the phone, and I say \"Hey, what are you doing here? I want to talk to you.\"\n",
            "\n",
            "The person on the other end says \"I told you, I'm going to the garage.\"\n",
            "\n",
            "That's when I knew. I knew that I am tired. And that's when I knew if I don't get out of these ruts now, my life will go to Hell too.\n",
            "\n",
            "I know that it's not easy, and it's not cheap.\n",
            "\n",
            "I know that the first thing I go by when I get off is \"my mom\" and \"dad.\"\n",
            "\n",
            "I know that I'm not going to make it.\n",
            "\n",
            "I get the phone and dial a number, but I don't even try to get through. I just make another text, \"I know where my mom is and what she's up to.\"\n",
            "\n",
            "And from that text, I hear something in the background. Not the kind of sound as I want the phone to make, but it's getting a bit too quiet and just kind of a steady vibration.\n",
            "\n",
            "================================================================================\n",
            "Model prompt >>> I should have slept more, but now my software code works.\n",
            "======================================== SAMPLE 1 ========================================\n",
            "\n",
            "\n",
            "\n",
            "We can say that this is the first experiment of a kind and it is just one step in the research. We only need to do one more experiment for each new proof of concept proof of concept, and also to test it with more users. I'm glad and thankful to all the people who tried to provide feedback and suggestions. We are grateful that these users can now experiment with new code, without any delay.\n",
            "\n",
            "\n",
            "I had expected my project, which is the biggest thing that we have to do in this decade, to take a longer time than expected. However, everyone here really, truly did their best in making this possible and I am really pleased and grateful for them. It also made us look forward so much to the future. I'm sure it's not my first problem in programming, but I am grateful for this project, which is the first experiment in the next decade.\n",
            "\n",
            "This is why I decided to announce this project at the beginning of this year. My dream for my project had already become the best of my dreams when things began to go smoothly. And today, I am so grateful and thankful that it seems the people could have been patient without any delay. It is so exciting to think that someday this project might succeed, too!\n",
            "\n",
            "I'm glad that we made it through this long process, and to say goodbye, I wish you all that great days ahead that you'll never have to see this world again.\n",
            "\n",
            "I wish you all that I've had the great freedom and the time to share this with all of you today. I thank everybody who believed and trusted in this. Thank you.\n",
            "\n",
            "All the best from the future and you very much,\n",
            "\n",
            "Federico T.\n",
            "\n",
            "This was the first and last post that you posted.<|endoftext|>It was an unusual afternoon for the Canadian Army.\n",
            "\n",
            "One hundred and one soldiers, led by two generals, were stationed in the small northern town of LeBreton Flats to guard a nearby road against an assault by a group of suspected Islamic State terrorists intent on executing a Canadian.\n",
            "\n",
            "Canadian military training had been suspended for the day, and a commando-style raid on a suspected ISIL member had the Canadian Armed Forces under constant guard for their entire career.\n",
            "\n",
            "Yet today's visit was about far more than the protection of the road. It was about bringing the country closer together as it continues to try to determine what exactly happened in a town that has taken the lives of Canadians since the 9-11 attacks\n",
            "================================================================================\n",
            "Model prompt >>> Invent a new musical instrument.\n",
            "======================================== SAMPLE 1 ========================================\n",
            " Find a new musical instrument for your wife to play.\n",
            "\n",
            "Give your girlfriend, a professional musician, a new musical instrument to play. She will make music every time.\n",
            "\n",
            "Give your husband a new musical instrument. He won't be able to perform at home when you do. It won't be enough. This would make you jealous.\n",
            "\n",
            "Take your wife out for a dance. Have her dance her heart out each time. Watch her make her own music. This is another way of keeping your wife happy and entertained.\n",
            "\n",
            "Your wife will spend money on everything you do. You have to start a business, you have to invest in your car, you have to take care of a house to be able to entertain your wife. This will give her a full day job that she has missed.\n",
            "\n",
            "Be very practical. You want her in the room, all day. She knows you are doing this because of her. You should keep her in the house. It gives her the best feeling, not to be in the kitchen, like you used to do.\n",
            "\n",
            "I want to give two lessons.\n",
            "\n",
            "The first part will just get you in shape and then you can work on other stuff.\n",
            "\n",
            "First you have to think about the things that you want to do. Don't forget your daughter's birthday party, for example. Do you think about your wife's birthday, do you think about the music, do you think about her family life, do you think about the things that you want to do? Don't forget all of this. I want to give you an extra lesson.\n",
            "\n",
            "One of the reasons I want you to be at home playing your wife songs is because music, and having your wife in it, is going to keep your wife happy. If I told you that she will stay home and just play her wife's music, could you imagine if she had to stay there all day? I guarantee you that your wife would do it too.\n",
            "\n",
            "In fact, I am talking about, what you do, not the things you do. Think about what you need to do.\n",
            "\n",
            "The second part of the lesson will get you to make your wife dance. It will take you back to the time when your wife played in music. You wanted her to play her music.\n",
            "\n",
            "I don't want to give too many rules.\n",
            "\n",
            "So in my last lesson I will cover a lot of things.\n",
            "\n",
            "When you listen to your wife play your wife's favorite music\n",
            "================================================================================\n",
            "Model prompt >>> Traceback (most recent call last):\n",
            "  File \"src/interactive_conditional_samples.py\", line 89, in <module>\n",
            "    fire.Fire(interact_model)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 141, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 480, in _Fire\n",
            "    target=component.__name__)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 691, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"src/interactive_conditional_samples.py\", line 71, in interact_model\n",
            "    raw_text = input(\"Model prompt >>> \")\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!chmod u+rwx src/interactive_conditional_samples.py\n",
        "!python3.7 src/interactive_conditional_samples.py --top_k 40 --model_name \"345M\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeDhY97XMDXn"
      },
      "source": [
        "To check flag descriptions, use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBaj2L_KMAgb",
        "outputId": "5e9389b7-924e-44d1-9ad3-dc33d2d77771"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "\u001b[1mNAME\u001b[0m\n",
            "    interactive_conditional_samples.py - Interactively run the model :model_name=117M : String, which model to use :seed=None : Integer seed for random number generators, fix seed to reproduce results :nsamples=1 : Number of samples to return total :batch_size=1 : Number of batches (only affects speed/memory).  Must divide nsamples. :length=None : Number of tokens in generated text, if None (default), is determined by model hyperparameters :temperature=1 : Float value controlling randomness in boltzmann distribution. Lower temperature results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive. Higher temperature results in more random completions. :top_k=0 : Integer value controlling diversity. 1 means only 1 word is considered for each step (token), resulting in deterministic completions, while 40 means 40 words are considered at each step. 0 (default) is a special setting meaning no restrictions. 40 generally is a good value. :top_p=0.0 : Float value controlling diversity. Implements nucleus sampling, overriding top_k if set to a value > 0. A good setting is 0.9.\n",
            "\n",
            "\u001b[1mSYNOPSIS\u001b[0m\n",
            "    interactive_conditional_samples.py <flags>\n",
            "\n",
            "\u001b[1mDESCRIPTION\u001b[0m\n",
            "    Interactively run the model :model_name=117M : String, which model to use :seed=None : Integer seed for random number generators, fix seed to reproduce results :nsamples=1 : Number of samples to return total :batch_size=1 : Number of batches (only affects speed/memory).  Must divide nsamples. :length=None : Number of tokens in generated text, if None (default), is determined by model hyperparameters :temperature=1 : Float value controlling randomness in boltzmann distribution. Lower temperature results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive. Higher temperature results in more random completions. :top_k=0 : Integer value controlling diversity. 1 means only 1 word is considered for each step (token), resulting in deterministic completions, while 40 means 40 words are considered at each step. 0 (default) is a special setting meaning no restrictions. 40 generally is a good value. :top_p=0.0 : Float value controlling diversity. Implements nucleus sampling, overriding top_k if set to a value > 0. A good setting is 0.9.\n",
            "\n",
            "\u001b[1mFLAGS\u001b[0m\n",
            "    -m, --model_name=\u001b[4mMODEL_NAME\u001b[0m\n",
            "        Default: '117M'\n",
            "    -s, --seed=\u001b[4mSEED\u001b[0m\n",
            "        Type: Optional[]\n",
            "        Default: None\n",
            "    -n, --nsamples=\u001b[4mNSAMPLES\u001b[0m\n",
            "        Default: 1\n",
            "    -b, --batch_size=\u001b[4mBATCH_SIZE\u001b[0m\n",
            "        Default: 1\n",
            "    -l, --length=\u001b[4mLENGTH\u001b[0m\n",
            "        Type: Optional[]\n",
            "        Default: None\n",
            "    --temperature=\u001b[4mTEMPERATURE\u001b[0m\n",
            "        Default: 1\n",
            "    --top_k=\u001b[4mTOP_K\u001b[0m\n",
            "        Default: 0\n",
            "    --top_p=\u001b[4mTOP_P\u001b[0m\n",
            "        Default: 0.0\n"
          ]
        }
      ],
      "source": [
        "!python3.7 src/interactive_conditional_samples.py -- --help"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8rSqkGxg5OK"
      },
      "source": [
        "Generate unconditional samples from the model,  if you're using 345M, add \"--model-name 345M\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaQUEnRxWc3c",
        "outputId": "88dff53e-2634-4aca-87bb-9daa0f1e6f05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From src/generate_unconditional_samples.py:52: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2023-01-04 13:50:12.909498: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2023-01-04 13:50:13.529370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-01-04 13:50:13.529970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2023-01-04 13:50:13.530090: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:50:13.530175: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:50:13.530262: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:50:13.530329: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:50:13.530391: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:50:13.530468: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:50:13.530542: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-04 13:50:13.530561: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2023-01-04 13:50:13.530953: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2023-01-04 13:50:13.535371: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2023-01-04 13:50:13.535640: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3132140 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2023-01-04 13:50:13.535674: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2023-01-04 13:50:13.716222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-01-04 13:50:13.717047: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3132840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2023-01-04 13:50:13.717083: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2023-01-04 13:50:13.717242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2023-01-04 13:50:13.717263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      \n",
            "WARNING:tensorflow:From src/generate_unconditional_samples.py:54: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/model.py:166: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/sample.py:65: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/sample.py:70: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From src/generate_unconditional_samples.py:63: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "======================================== SAMPLE 1 ========================================\n",
            "Data from all 205 Hiroshima-kai-kai games. Thor and Broma are not included.<|endoftext|>Sometimes it really does feel like they changed the principle of the model because now we know how the status quo works in many situations.\n",
            "\n",
            "When I made a post about Speculative Drop 2.0 back in December, I had no idea you could keep missing the deadline for Citicorp to honor your $2,500 check in 4 weeks! But check your calendars, because there's a couple amazing deals to be had right now and you can make your bonus in March! Even better than that, there are some interesting assists available from combining those two deals to help you buy new tools- including deals like this one that lets you buy all 4 Relays, and cash them in in One Year for even more bonus money! If you have been shopping lately then be sure to check back and see what deals you see as liquidations vanish for every bank and CYA division.\n",
            "\n",
            "In the end, you stand to recieve roughly $400.00 for Citadel, Insurgent, or Datacenter- after already spending over $470.00, again, on Citicorp tools since when has they ever reduced the delay by 400%, even on this small time frame?\n",
            "\n",
            "Think of it as 10%+ more than what you paid for ALL CITICORP CUSTOMERS to SHIP.\n",
            "\n",
            "Some note, though, that Citicorp may, for various reasons, be able to do more expiration effects, like any sales partner, even when it's your money. I'm pretty sure that any time you get more than 15 days out of your payments? And you attribute all of your problems to the fact that it didn't go your time?\n",
            "\n",
            "Well, operating is money-losing, so for all you rich materialists, you're not entitled to 80% appreciation for this leverage you're paying him for.\n",
            "\n",
            "You should just LOVE this fact:<|endoftext|>Submit Benchmarks! Submit SSD Benchmark\n",
            "\n",
            "Submit GPU Benchmark Compare any two graphics cards: GeForce 810M GeForce 820M GeForce 825M GeForce 830M GeForce 840M GeForce 920M GeForce 930M GeForce 940M GeForce GT 1030 GeForce GT 240 GDDR5 1GB GeForce GT 640 DDR3 GeForce GTX 1050 GeForce GTX 1050 3GB GeForce GTX 1050 Ti GeForce GTX 1060 GeForce GTX 1060 3GB GeForce GTX 1070 GeForce GTX 1070 Ti GeForce GTX 1080 Geforce GTX 1080 Ti GeForce GTX 560 Ti 448 GeForce GTX 650 GeForce GTX 650 Ti GeForce GTX 650 Ti 2GB GeForce GTX 660 GeForce GTX 660 Ti Geforce GTX 670 Geforce GTX 680 Geforce GTX 690 GeForce GTX 750 GeForce GTX 750 Ti Geforce GTX 760 Geforce GTX 770 Geforce GTX 780 GeForce GTX 780 Ti GeForce GTX 850M GeForce GTX 860M GeForce GTX 870M GeForce GTX 880M GeForce GTX 950 GeForce GTX 950M GeForce GTX 960 GeForce GTX 960M GeForce GTX 965M GeForce GTX 970 GeForce GTX 970M GeForce GTX 980 GeForce GTX 980 Ti GeForce GTX 980M GeForce GTX Titan GeForce GTX Titan Black GeForce GTX Titan X GeForce RTX 2070 GeForce RTX 2080 GeForce RTX 2080 Ti Nvidia Titan X Nvidia Titan Xp Radeon HD 7750 Radeon HD 7770 Radeon HD 7790 Radeon HD 7850 Radeon HD 7870 Radeon HD 7870 XT Radeon HD 7950 Radeon HD 7950 3GB Radeon HD 7970 Radeon HD 7990 Radeon Pro Duo Radeon R5 M230 Radeon R5 M255 Radeon R5 M330 Radeon R7 240 Radeon R7 250 Radeon R7 250X Radeon R7 250X 2GB Radeon R7 260X Radeon R7 360 Radeon R7 370 2G Radeon R7 370 4G Radeon R7 M260 Radeon R7 M260X Radeon R7 M265 Radeon R7 M360 Radeon R9 270 Radeon R9 270X Radeon R9 280 Radeon R9 280X Radeon R9 285 Radeon R8 350 Radeon R8 370 2G Radeon R8 370 4G Radeon R8 M260 Radeon R8 M260X Radeon R8 M265 Radeon R8 M360 Radeon R9 270 Radeon R9 280 Radeon R9 280X Radeon R9 285 Radeon R8 360 Radeon R8 370 4G Radeon R8 M260 Radeon R8 M260X Radeon R8 M265 Radeon R8 M360 Radeon R9 270 Radeon R9 280 Radeon R9 280X Radeon R9 285 Radeon R8 360 Radeon R8 370 4G Radeon R8 M260 Radeon R8 M260X Radeon R8 M265 Radeon R8 M360 Radeon R9 270 Radeon R9 279 Radeon R9 280X Radeon R9 285 Radeon R9 290 Radeon R9 290X Radeon R9 295X2 Radeon R9 380 2G Radeon R9 380 4G Radeon R9 380X Radeon R9 390 8G Radeon R9 390X 8G Radeon R9 Fury X Radeon R9 M265X Radeon R9 M270X Radeon R9\n",
            "======================================== SAMPLE 2 ========================================\n",
            "With investments in New York, Wall Street and for-profit colleges, the program is set to reap widespread returns as its dollop of federal dollars buys for-profit universities well-documented for their environmental crimes. Find out how much your money's going to buy if you try to sit A Year at NYU, Cornell or the University of Chicago. Then show your head to U.S. Citizenship and Immigration Services, which belongs to Wall Street.\n",
            "\n",
            "Jonathan Adams, an assistant professor of business and public policy at Princeton, published a paper at Grist that describes the illuminating filters on which taxpayers upgrade for-profit educational institutions: The way the government filters out information has tilted the scales in favor of corporations over public universities.\n",
            "\n",
            "Here's the rub of this educational filter: Dominate the market and the American taxpayer will wait, like a straight-laced goldfish, for movie director Will Ferrell to throw in $100 to buy a picture audition for \"Exchange.\" Meanwhile, public universities, going through buying cycles, have become the Skatellites, as Curtis Goldsmith and Edward West have dubbed the industry.\n",
            "\n",
            "Roi Guerra, director of UIC's public costs division, said she's pretty sure the figure is public sir. A couple of years ago, she put on a white cap exposing her finger in an effort to imprint light where paper, certification shots and other certificates are invisible. \"We ran into trouble, but I managed to cut through that registrar bullshit,\" she acknowledges now, pointing to a narrow hill in front of the massive university building next to Jewry that offers views of the East River and similar tourist attractions. \"This [meeting] was the most positive and I received the full cost of all the affiliates who attend it.\"\n",
            "\n",
            "Many scientists and their student guides never adjust the focus of their work to what the DOE calls 'intermediate campuses,' while students from the background look at Apple stores (they're easier to access for industry) in The Everglades. According to University of Illinois sociology professor Brooke Grarrant, \"Barristers regularly seek processes configurations to get the attorney's fees and lawyers' costs back,\" while paging through glossary iGoogle by way of Clinton A. She writes , \"The DOE investigation sorted out grandchildren, like my granddaughts, and put $18K of legal fees on my kids' academic record. In turn, they will likely try to bolster the Corinthian schools' reporting expenses... Even Mark Warner and colleagues at the Justice Department downlinked these private school entities when all knowing parties requested video background checks of these companies.\"\n",
            "\n",
            "The Times' Mark Berman wrote that \"video backs\" cause similar challenges, meaning that these state regulators can, essentially, order a physical copy of videos viewed online to end up in various internet databases, while JITM, forbearance, production and bookings books — to the point where those sources are handled by independent organizations. and those sources are handled by independent, non-profit agencies.\n",
            "\n",
            "A recent Wall Street Journal op-ed, \"Corinthian Colleges' Profits, Cookies, and Myths,\" highly speculates that the POUM voted on of the two schools populate including at Columbia, lest investors jump straight to the Gates Foundation-funded, scene-hyped New York-Harvard-University of Chicago-reputed system.\n",
            "\n",
            "Several \"enterprise grade\" universities were named as contacts directly. Of course, this level is highly their would-be competitor is catalyzed by its parent's eventually-to-launch so called \"ambassador\" unit, Office for Leadership & Mission Development Mints and Shops (OND-M), which was named to be uptropical and attract students from other cities. \"We drive the student recruiters each season,\" senior academic Diederick Mullins, a member of the executive branch nomenclature council, told the Daily Advertiser in spring 2006. \"We see potentially certain teachers depending [on] how far we graduate.\" That's great for the thought to countless students who think they can rack up the courses their godfathers kickback. No lesson more clear doesn't get broadcast like it will in view everything.\n",
            "\n",
            "Wilbur Kalb, a spinster professor at the University of Wisconsin, whose students benefit from his understanding of their (Kentucky to DC yields too many Count head loads) ineligibility ways , and Marching Agreement with MBA programs, said \"a giant percentage\" of his students and their host institutions are considering continuing their educations beyond the schools the DOE Fifty and no PLF applied for renewal. I don't know of any other educational organization in the country that can apply for renewal that said, \"This country (or at least the 21st century) is not perfect.\" Where else can big money roll in by dazzling students and their hospitals and universities?\n",
            "\n",
            "One group of alumni, who looks forward to their direct access to \"chattels\" for the U of C has counselors working in a local\n",
            "======================================== SAMPLE 3 ========================================\n",
            "PRINCETON, NJ -- Americans fear Iran will strike the U.S. at any moment, believing that it is generally more likely to oppose U.S. military strikes in the forum of war but that it may change its mind at the last minute because it feels it walked into the trap of air strike while learning it could not close the loopholes. That is supported by majorities of Democrats and Republicans who fear Iran was going to attack if the United States went to war in Cuba before it decided against it. Even if the Iranian regime wanted to go to war in response to the president's making an apparent partial acknowledgment of American war powers on Iran, it is unlikely that it would carry out such moves, because Iaggard's press conference announced that ink on paper was the last frontier price upon which there was struck. If the voters of Colorado, Arizona and California are right, that gives voters confidence that the result of the primary contest is likely to be different from the results of the November election.\n",
            "\n",
            "On partisan balance, there was no great shift in partisan fear since the closure of the two possibilities: Democrats' grip on this sector of the electorate is stronger than the grip of Justices Sonia Sotomayor and Elena Kagan, in another construction to the sentiment compiled by Senator Bob Corker of Tennessee, No. 2 overall on the so-called drug enforcers list, with 79% saying this. However, on partisan judgments about where foreign entities will continue to treat Americans, Republicans now hold such majorities as Democrats do not. The threat vaporized in a Democrat's prison remarks from a Clinton supporter:\n",
            "\n",
            "I really don't know this... which of these two is likely to be more damaging to our nation? It may well be that we receive the 50 percent of IRS agents who really want to reach out to progressive groups helping reduce costly and intrusive government programs. But it's hard for me to say if that would be the case with Hillary Clinton and if it would be with a president who wants to destroy this technology.\n",
            "\n",
            "MORE\n",
            "\n",
            "0830 24 Jul 2001 WALF A/HILLARD L/BRILLJAN The Senate voted to accept committee's proposal to delay or extend as long as six months... establish science academies, strengthen academic competency codes... poised to increase college enrollment and to afford as much help and assistance to terminally disabled, confined students as possible.(WORKING CHARTS Reporter, News, abstract, 27 Jul 2001 Failed to find statement from the Senator on whether he accepted the Com- mittee's proposals.) CCC JOINED ADDITIONAL LETTER-OPS DISCUSSIONS OF STUDYING WOULD THIS ENFORCEMENT BE CONSIDERED RUDDLING? (COMMITTEE SCOTT STALLMAN. NOTES. 16 Jul 2001 Did the Senate vote to pass committee's \"study\"? Lost 17 Democrats, identifies the parent would vote for if decision had been made to pass the study. 1100 26 Jun 2001 WALF A/HILLARD L/BRILLJAN The Senate approved bipartisan legislation... a motion to resubmit COVENANT, not add it to endless debate. Enacted in Committee Chamber on 28-27 \"H\" Enacted in Senate held in 285-2015 Verdi FONT JULY 13, 1986, to February 3, 1989. The words 'given to' and 'incorporated' are to be used with particularity in all procuring of ever-increasing compensation for extraordinary longer salaries than are paid to civilian researchers, specialists, supply officers and consultants.... Citing ``significant deterioration'' of science life and publishing ''political contumm Employs - believe ponies on an event to have been most newsworthy during the war. Drilling plans can jeopardize research staff/firm safety although the CIA reserves the right to defend its research in servicing a national security resource..... Obviously, 11 of 15 researchers in the field left the service by the time MONDON ATTACKS ROLLED IN. (Dennis G. Pierson, Chief-1st Lt., USAF, University of Texas. struct eng cause when his Klondike train could defeat the morning blast threat, cops rapes wife, he had SA's courage.) (Charles Sy , Aviation Logistics Service. Int. NOX B66MA599. 13 Aug 2001 Selected new report outlines increase in UFO activity since the end of WWII. MIOM DEC. 11, 2001. \"Liev Herrig. The confusion generated by the ever-increasing number and performance of 'high potency' plants slightly diminished the prevailing pessimism about the potential motivation underlying the anomalous study if emphatically stated generally. .... More than to Puerto Rico would the President be taking the day off? More than even to Colombia? Of course not! No cause could justify suggesting such long inactivity by him for any single day!\" At the same submission has the following.ently to fill this action sentence. Ignored by those reading the full text could not, according to James Valenti the commanding General\n",
            "======================================== SAMPLE 4 ========================================\n",
            "Photo by Gage Skidmore via Flickr\n",
            "\n",
            "People are having sex — and not naked.\n",
            "\n",
            "The Huffington Post scored first with a headline on Monday: \"So You're Out of Body Sexvids? See for Yourself.\" Begun on the group site Democratic Fun, it reads more like a fetish site than a news web site. The theme is Spanky Nostalgia.\n",
            "\n",
            "The concept is the same. Users offer up brief audio, text, and photographs of a dripping finger, fingernail, or wart, alternately touching and kissing it for a pair of cues to include that they've emptied. It's not due out until Fall and is priced in at $25 for three minutes.\n",
            "\n",
            "In the interim, all are free to do so on the site, but who lives in a world where this is normal? Your tax-exempt tax dollars forced this across the line.\n",
            "\n",
            "The National Gay and Lesbian Task Force produced these sexually explicit images:\n",
            "\n",
            "SPONSORED\n",
            "\n",
            "Two thousand\n",
            "\n",
            "\n",
            "52\n",
            "\n",
            "\n",
            "When it was straight, two thousand and one.\n",
            "\n",
            "Fourteen\n",
            "\n",
            "\n",
            "22\n",
            "\n",
            "The line: \"Fourteen.\" As a prior item, no. I take a picture of everything I see, everything. And if it's lesbian sex, I draw it. Remember looking in the mirror, in real life?\n",
            "\n",
            "Set of six\n",
            "\n",
            "\n",
            "A bundle of eyeballs. I went through a lot of stuff to try to draw them large, pin-prick them with one hand.\n",
            "\n",
            "One and a halfs\n",
            "\n",
            "\n",
            "No, this is conjunctive. I want to see the whole bundle of seven between my eyes, experience its stringy bottom right there for me.\n",
            "\n",
            "Jug\n",
            "\n",
            "\n",
            "Yes, that means like, a jug of piss. Good food, sure.\n",
            "\n",
            "And, where it succees to be...\n",
            "\n",
            "Leviticus tablet\n",
            "\n",
            "\n",
            "...a fifteen-gilled fondant for tickles.\n",
            "\n",
            "Meanwhile, all over the NFL, Mel Kiper Jr. put out a top-ten NFL mock draft in the Post as well, predicting Pierre Garcon, DE, the fourth most popular pick.\n",
            "\n",
            "O\n",
            "\n",
            "E\n",
            "\n",
            "L\n",
            "\n",
            "D\n",
            "\n",
            "J\n",
            "\n",
            "T c\n",
            "\n",
            "\n",
            "A more funny headline, but it does seem to signal a big media soul: HARDER WORKFORCE.\n",
            "\n",
            "Aethetics.\n",
            "\n",
            "Country.\n",
            "\n",
            "Where!\n",
            "\n",
            "NY.\n",
            "\n",
            "Pleaseucci.\n",
            "\n",
            "Read Other Articles From The Huffington Post<|endoftext|>World Cup 2018: Netherlands key to Europe's stuttering rebuild\n",
            "\n",
            "TOP STORIES\n",
            "\n",
            "Finland flounder is missing deep down\n",
            "\n",
            "Samus Leyden gets even with Rogue Ryder after brain throw\n",
            "\n",
            "Say patience with Randy Couture\n",
            "\n",
            "PSG legend saves from Eder\n",
            "\n",
            "Money Magathakhsh tangles briefly with Swedish game presenter\n",
            "\n",
            "Mamashipoly has a few things on his mind\n",
            "\n",
            "Jayos has time to prepare for pain<|endoftext|>The eclectic American flower industry is known worldwide as \"The Field,\" with the growing inventory of practitioners and alluring sightseeing enthusiasm. This lengthy in-depth exhibition celebrates small accommodations, masterpieces, a few of the production artists (of any profession) and their sun among exotic showpieces. The artists are patrons of the \"Field\" of this industry, posting reproductions and in prints, illustrating, demonstrating, and framing work. Among them are allToronto's professional floral women, that lovely and diverse pastime it, namely the curvy, eclectic summoning of clients and their gold-plated rooms. Through its Candice at Marco Lazzari show, the exhibition was the spotlight of British Photographer and Great British Vegetuality writer A.M. Phipps.\n",
            "\n",
            "\n",
            "Scotch motifs on the panels for the photography, Kyembot argues that when materials like glass are patterned beyond comprehension — ready-made and needed well into the industrial age — then the \"nothingness of the material to create an existence\" if used doesn't really matter and nothing of its own submits to (and is perfectly matched). There can be no other way, wrote Phipps of Dr. Cruz, canvas pattern is like music: \"the juxtaposition of whole sounds with atomic modes.\"\n",
            "\n",
            "\n",
            "Given the points written, nothing can be missed (\"A lunar talentless profile, a nervous beard sullenly surrounded...\", read the packaging). Such negatives as readings that do came laden with lots of errors or , and multiple responses provided the rare brilliant perspective. The written piece felt one senselily incredulous: \"Carrying cards of a green-and-black shojiallioadyrielyiolly. Could not be beaten...\". Improspective parleys were somewhat intimidated by fiction as it is from many others. Yet questions frequently roamed the dark, as if have it not been the case for countless atlases? Written especially is editorial clairvoy\n",
            "======================================== SAMPLE 5 ========================================\n",
            "Published August 2005\n",
            "\n",
            "\n",
            "University of New Mexico Law Review Book Reviews\n",
            "\n",
            "\n",
            "Legal Ethics in Western Medicine\n",
            "\n",
            "Flowers and Flowers Elu Butters\n",
            "\n",
            "Norman Esterson, University of North Texas, Dallas, TX \"The legal ethics of Western medicine in the West is documented, and in this book I stand as proud advocate for medical causes according to the natural law and upheld as such by my opponents. The authors cite 18 paradigmatic of the \"five kinds of people\" - atheist, agnostic, evanescent, religious, and voluntary - well as G.K. Chesterton's 'Church and State',...\n",
            "\n",
            "\n",
            "Defensing the Persecution of Jews in Western Medicine\n",
            "\n",
            "Marianne Ireland, University of Denver, CO The author carefully examines the charges against both Jews and Americans and provides an extensive review of 8 pertinent books. She analyses the Jewish attacks on individuals and remedies the Jewish complaint of innocence founded upon the creation of the Jew-house, the Jewish attempt to create stock of saved Lazarus and their ridicule of the therese's marital arrangement between the son of Pharaoh and Ena of Arbela of Arabia. They explain Christianity in its context of the false and double creation to cover up the human groundwork in Genesis as the basis of the pretended Jewish war on God. They analyze at great length the allegations that play here, doubting the evidentiary base for the motive of defence. They blame 'the wholesale inculcation\" of Jewish values in American families as well as in the medical community.\n",
            "\n",
            "\n",
            "Language Legal Ethics\n",
            "\n",
            "Victor Ibrahim, University of Wisconsin-Madison, Madison, WI The \"Ibrahim\" book provides a comprehensive assessment of different bases of Bodily Rights, as western statutes define them they go beyond the routinely classified races and ethnic groups. He also says that blood transfusions are based on 'vexed benevolence'. They subject every 'Virgin Exodus' detail of recovery, post traumatic stress, secondary or tertiary stress, in \"et fertilized wombs\", to strict liability and more generally a very old oppressive diagnosis. So, the person gets reasons as well as the facts, but humans throw arrows at one another through their language, the language we use according to a 'wired'.\n",
            "\n",
            "\n",
            "The Ruling Class in Western Medicine\n",
            "\n",
            "Chad Vasilyev, McGill University , Montreal Review of Law and Ethics, 1992, Cambridge\n",
            "\n",
            "Dr. Vasilyev contends that all Western medicine is a for-profit enterprise, controlled sources of profit, labor, and surplus is to be made and is to be used as a tool for controlling \"dangerous\" people. To control and reduce non-controlled targets (whom the commercial, sociology and public relations industry arranges to be 'unreliable' so that corporations can sell), leaders who have inculcated henceimage of themselves as (and some sort of emotional bonding with) those future 'curators' of 'dangerous' people must renew and extend a limp rhetoric that recreates the society they have mercilessly re-ordered and aspired toward that is designed to conform with the ideological will of self-serving leaders of the future.\n",
            "\n",
            "Gary Bloom –Dr. Bloom & Minas Panaderakis Press, New York, NY \"If there ever was a bad lawyer, it's Gary Bloom. Never was his profession so notoriously sycophantic -and in matters before the courts - and I agree totally with the fact that simply eliminating Gary Bloom and bringing his posterity to the fore won that patent on monetary palmistry, certainly.\"\n",
            "\n",
            "Herman Whitehouse Comparison\n",
            "\n",
            "Corey Blackwell, Western Affidavit (March 2000) The audiobook version can be downloaded from http://www.orig.efstra.edu.au/hw/cdb/wadfiles/archive/CDB00012844.rar\n",
            "\n",
            "\n",
            "Jason Rohrwink from MERS awareness\n",
            "\n",
            "The newspaper abot \"49\n",
            "\n",
            "30\n",
            "\n",
            "And 245\n",
            "\n",
            "33\n",
            "\n",
            "2\n",
            "\n",
            "57\n",
            "\n",
            "8\n",
            "\n",
            "13\n",
            "\n",
            "28<|endoftext|>Leader Skill (Awakened): Adds Benre (150% Attack and HP).\n",
            "\n",
            "\n",
            "17/16/24 NAT/SPD/DEX V, BB/DEX/SPD/DRK VFA6+, when using Benre, inflicts 434% damage (155% total), related to Benre. 16 12 12 13 12 12\n",
            "\n",
            "Overwhelm (100%, 1 Time): ↑ U-turn clock 1 sec.\n",
            "\n",
            "\n",
            "14/13/14 NAT/SPD/DEX V, PHY/SPD/DEX/SPD/MPF/BLK VFA6+, decrease enemy's Defense by 25% for 2 turns MinBreak: Delay 2 turns. 7 13 11 13 11 13\n",
            "\n",
            "Second Armament (120%, 1 Time): Human/Flip Stance attack +3. ↓ Shinto summons (4 allies) at all times. Damage chosen at 5* damage multiplier and used\n",
            "======================================== SAMPLE 6 ========================================\n",
            "Cheap Drug Prices on the Upper East Side\n",
            "\n",
            "What's Not to Love on the Atob:\n",
            "\n",
            "You wanted quick facts, Spense! If you are as spongey as I am as a reader and a number of you do have these goods in your stash for now I will try to make myself clear based on middle class folk's conversations with high-priced low-skill, middle-management shoppers. You want all that. I am not trying to save you from only some of the problems here; I'm going to list them all and build you up, just there on paper on your Facebook wall.\n",
            "\n",
            "Much of what business owners tend to sell relatively low-end is also what is on the debut floor. Michael & Wendy, Frédéric and David's insurance shop near the Financial District is best-known for its evidence-based medicine and as separate from Louis Vuitton as you can get. I, on the other hand, lost track of the size of many of the items listed there initially, but I followed the approximate trend up as far as it went even with \"M-Coch\" shoes, comfortable sole cowboy sandals and a cross between pink and Hispanic dropping. Everything is curled 210 (check out The Spokes' Price Guide for the price of things).\n",
            "\n",
            "\"Taffy\" rentals for too used plastic bottles, of course for throwos like you.\n",
            "\n",
            "cranks of cocaine in cubes or large, sturdy goblets.\n",
            "\n",
            "Magazines for someone more interested in short ribs on a compact shelf. If you make employment or pension plans it's quite much in a clearing next to a handyman.\n",
            "\n",
            "Strange pearl-handled, glass water bottles which look much more Cartier than even the most quotidian 'serviceable' bottles usually look. The problematic straw smaller than the one listed in one of the first three paragraphs of a brand photographed in a Military Tattoo Institute of Ordnance folder seems to be any 752 proof Orto Vera, but it's impossible on, that's the Brand.\n",
            "\n",
            "Plastic mint-looking lights, one show light really loud, which looks like it could emit an infernal symphony to the outside world if left on all nightlong.\n",
            "\n",
            "not coffee filters those of you familiar with the French phenomenon mints. I got two of them for $28 and a perese stake of my signature on the label. (One was just examined before it broke and sat on the burner; the other was part of a package of about 300 appears to have counterfeited out of the French version, the most transparent, and appeared out of place wallpapers for many bakeries.)\n",
            "\n",
            "How else will they afford it? Gerber had one of these and people didn't really offer you another, I imagine. I couldn't locate a price listed.\n",
            "\n",
            "The Trappist of the East had one of these soda can rose-colored beauties. \"No wonder they thought it absolutely beautiful to sell overt birthday tributes under the Adele name,\" ha ha.\n",
            "\n",
            "This little Marley Watkins (an old Ru's kit junkie salesman's mother) could have a green-colored spool for me but in her line of work she uses blue or pink stuff. The family usually writes baskets for everyone so they may have got one right out of Ress like the Chat Slave being kept in his box, though with the Cult played on the outside of the box.\n",
            "\n",
            "Merry reduced nic controller. Each one has unintended telo levels attached to a little bulb and potentially bad alcohol or fuel ratios. I didn't use when I needed candy, what's left is to clickety-boo-sdzenked me to think twice about value for life when I plugged in.\n",
            "\n",
            "I have to think it was no You make a fine Mr. Aholigan, \"Pack it right into your own room\", Judy Wallace began in later years during the big cold water trade. (I like that great line, so I wrote long, humorous less-loud people's edu-screwings to it later.)\n",
            "\n",
            "Caribbean duty-free (but I like it back in the good old days, girl!), H > NG softened by CK Tet Couch, curiously there are nine different La Hombres in this cordial-goods bundle.\n",
            "\n",
            "This Chinese Drum sold for about $30. Don't expect real Chinese drums, miss, it's on the backside of my Fami club shorts. For what it has sold, that is. One $80 receipt will down-ville all that Chattanooga Crap Gold (other than the bloody five already on upping prices), but only three will include the four public mentionings of \"That was the best meth ever, Frontier Fried\" and Yen Dong worries about gist vagenium . . . I rather like that emptier charge.\n",
            "\n",
            "The mysterious Hong SunVi and Szechuan Panic kept on me, I agree.\n",
            "\n",
            "Well, can I have\n",
            "======================================== SAMPLE 7 ========================================\n",
            "The following is a guest post by Army Ranger Neumark Dale, who retired as a Commanding Sergeant, major, and a former field commander and field instructor in Afghanistan and in Abu Dhabi, and is now a Foreign Service Officer at the CIA.\n",
            "\n",
            "Turkey, March 15/2016\n",
            "\n",
            "Though few in nor out of the broader security community in time of war tend to see ISIS as the enemy of the nation, their methods of operation have done one site's insurgents in every major city in the region three of their six-year economic boom. They have taken enormous advantage of the country's porous borders by using cargos and rail from non-peripheral sources to land their illegal drive to control large chunks of land—right on the doorstep of enemy cities. Hurriyet Daily News and Yeni Safak daily reports on the action in Nice, France, where a Tunisian-born ISIS fighter blew herself (again) in front of the Eiffel Tower, just 700 meters from higher ground. No such jihadi took her life in order to gain the attention of the newspaper, but just before that, on July 17, three Middle Eastern elders in Iraq had been shot by a sniper, and were selecting bodies to go to the morgue. Shells, sandbags, and the stench of the corpses echoed up and down the street. Not far away, in Baku, Azerbaijan, a Fatah minister murdered by an ISIS suicide car bomber attempts to once again launch a suicide attack in the House of Representatives. Explosions aren't typically the major attraction of ISIS-related intra-firm warfare in Nigeria, but the Bizishan 942 attacks of March 16 against five governments—more than twenty-five months before Nigeria opened up about the purported involvement of this country in another series of deadly attacks on citizens that soon became known as Boko Haram—display many of the same symptoms of incomplete focus and neglect in a country so vulnerable, yet so eager to label its enemy.\n",
            "\n",
            "In both instances, various Nigerian targets from around the world were either at risk of falling victim to the violent fanaticism of the radicals or they were at risk of just being one of terminal exhaustion. ISIS is home to twelve terrorist cells operating in the greater region, and more are thought to be actively resorting to terrorism in opposing areas. Yet, in spite of ISIS and AQI's significant foreign presence and allied resurgence in the regional prison system, Nigeria long ago fashioned a better, less truculent form of police competition among its myriad development institutions. Today the \"Belly of the Beast\" generally excludes religious groups, church administrations, and tribal authorities while visitors staying in good-repair hotels must be careful around what receivers of short $10-a-night rooms and room for two bet over only the call to prayer can carry out. In practice, the Nigerian state-run-law-services program is badly depraved, enraging and impoverishing, heavily lowering attempts towards justice against numerous political offenders. With middling government insurance and abysmal state supervision of wary private sector bastions, Boko Haram's attempt to establish its terror laws went right down to the colonial kitchen and into the kitchen drawer.\n",
            "\n",
            "While the region's capital itself went a clean sweep of Boko Haram, known alternately as the Maiduguri government and the Maiduguri State, their original operation in Yobe, specifically in Orkneys – near the United Kingdom immigration region–(www.ninnmongDerby.com), the First Army specialist in operation in Bodom was directly involved: he was killed by a bullet to the gun in his hip and a leg wound (variously described as wildly as a leg wound explaining a leg wound…) in his stomach below the knee, on March 15. 32-year-old Guido Reinhardt had expressed no concern for the victim, but in the ensuing confrontation managed to move some weight behind family. The Baiji suicide bomber was accused of hiking a child to a telephone pole and in his wheelchair as he detonated, killing he and wounding another. At 3:15pm security forces again targeted the small village of Baybars, a lone deep cut deep in thick scrub away from the city, again as the shaken-up welfare state officials operated treat parts posted outside the (suicide) call center. This time, 20-year-old Enteni Akilefeid (name changed) took 12.\" Four days after the assumed urban rampage, Haroon Rashid bombed a government office in Maiduguri's constituency Sarangani, destroying his own office. Fasting from the violence in two very different ways, the local media expressed more different sanction than had been customary during the first eight weeks after the violence. Says leftist representative Nahdlatul Alam had been somewhat less protestated in his message than during a similar rampage (namely, that the Egyptian bus al-Nahouk which had two explosive devices yesterday was Abdel Hameed and he had repeatedly said his driver spent his nights at his house there). Though consumed\n",
            "======================================== SAMPLE 8 ========================================\n",
            "New MBTA management says officers reroute patrons after that mass shooting\n",
            "\n",
            "It was a holiday weekend in 2009 and in the largest subway station in Dublin, passengers trampled one another as they tried to board or disembark at the busiest station in Boston.\n",
            "\n",
            "Five men who carried out the unprovoked attack pleaded not guilty Wednesday in connection with the death of an 84-year-old man involved in a wheelchair, friends said.\n",
            "\n",
            "Mark Lenton, 25, and Steven Fletcher, 29, carried out the attack that left the victim bleeding to death, feared fatally but in good reasons, then ran off, hunters and police said.\n",
            "\n",
            "Advertisement\n",
            "\n",
            "It ended a rampage that left the attacks suspect who was shot dead and the 84-year-old man seriously wounded, prosecutors said.\n",
            "\n",
            "Get Fast Forward in your inbox: Forget yesterday's news. Get what you need today in this early-morning email. Sign Up Thank you for signing up! Sign up for more newsletters here\n",
            "\n",
            "Neighbors identified the victims as Matthew Crane, too elderly to do the same.\n",
            "\n",
            "Matthew Crane and Steven Fletcher are alleged to have killed a man who waited at the Boston bus station before leaving, according to William H. Coburn of the Suffolk County District Attorney's Office.\n",
            "\n",
            "Lenton, a longtime writer and musician from Newport, Maine, was a \"wherefore report\" type, he said, as described in court documents. He was roofsetter before suffering a brain injury, he said, and had been at the station for days, accommodating people.\n",
            "\n",
            "Advertisement\n",
            "\n",
            "Somerset District Attorney John J. McMahon released a statement in reference to Lenton, saying he was a \"100-percent innocent and courageous person equal parts veteran, advocates, actor, leader, sportswriter of rock music, printer, and father.\"\n",
            "\n",
            "Mark Colston, the 58-year-old man shot and killed in the lodge on Wabash Avenues, where more than 50 people fell ill that day, is the alleged shooter, as are Stefan Chamberlain and Michael Walsh, the stolen pal who took the license plate from Anthony Weiner.\n",
            "\n",
            "Both were warrants for several months.\n",
            "\n",
            "Lenton recently converted to Islam and had gone into treatment and silence, family members said.\n",
            "\n",
            "In Colston's case, his guardians asked a judge to send him to Foxwood Hospital Gray streets on Disabilities for treatment.\n",
            "\n",
            "Shortly before 5 p.m. on Christmas morning, relatives and police said, they discovered a wounded man in his wheelchair was standing at the Cincinnati Hospital on Spring Garden Avenue.\n",
            "\n",
            "Advertisement\n",
            "\n",
            "Social Security benefits indicated the man had a heart condition so doctors worked to remove six large blood vessels from his heart. The soldier, arm and leg in Stoughton, had to amputate his right leg.\n",
            "\n",
            "As the Chair of Boston Hughes Congregation, Lenton wrote on Facebook about how readers gleaned his Twitter posts since the attack.\n",
            "\n",
            "Pedestrians are dazed as suspect in Boston bus incident works to open doors saying \"\"Mardi Gras\" and \"Father Gonna Take Care of It\"❤️board my boat beyond python hope.\" pic.twitter.com/LNQbYwKMcO — Ambrose Brent (@amelanettmichaels) May 28, 2017\n",
            "\n",
            "A man who answered the door as someone described him, knew little of his family. Most passersby who asked Lenton if he was father million times were not his friends, he said.\n",
            "\n",
            "It has been that way since between 1993 and 1998, he said, once when he contacted Boston police, twice when his wife learned of his public statements. And people around Boston that couple does not know float by. \"The more you do the more you understand,\" he said.\n",
            "\n",
            "\"I feel for completely only one person\" ?a death or injury victim\n",
            "\n",
            "Up until the attack, the bus terminal was open, readers told us. Now its closeds.\n",
            "\n",
            "Commuter Leonoy Leong said a man is what's left of the world in East Ile Street Station after a violent outburst of four days and three nights after a Friday suicide spree.\n",
            "\n",
            "Advertisement\n",
            "\n",
            "He told us the man worked a brokerage and was a dedicated driver for the bus company. On a Train Editboard, he would mention \"Mardi Gras\" and \"Dad Gonna Take Care of It\" once there every three years or so, he said.\n",
            "\n",
            "\"Some days there's no calendar, four days, three nights. That's crazy but also from a distance.\"\n",
            "\n",
            "\"A man like him is what's left of the world in East ile Street Station after a violent outburst of four days and three nights after a Friday suicide spree for you to think I have never seen anything like it before. It's if they wanted to travel in countries, what sort of thoughts would they have?\"\n",
            "\n",
            "He said Lenton was laughter-treading before and had had a history"
          ]
        }
      ],
      "source": [
        "!chmod u+rwx src/generate_unconditional_samples.py\n",
        "!python3.7 src/generate_unconditional_samples.py --model_name \"345M\" | tee /tmp/samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VM1Hag-JL3Bt"
      },
      "source": [
        "To check flag descriptions, use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sdxfye-SL66I",
        "outputId": "f080f34d-bf60-42d0-89c0-00f94a907423"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/AITestKit/gpt-2/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "\u001b[1mNAME\u001b[0m\n",
            "    generate_unconditional_samples.py - Run the sample_model :model_name=117M : String, which model to use :seed=None : Integer seed for random number generators, fix seed to reproduce results :nsamples=0 : Number of samples to return, if 0, continues to generate samples indefinately. :batch_size=1 : Number of batches (only affects speed/memory). :length=None : Number of tokens in generated text, if None (default), is determined by model hyperparameters :temperature=1 : Float value controlling randomness in boltzmann distribution. Lower temperature results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive. Higher temperature results in more random completions. :top_k=0 : Integer value controlling diversity. 1 means only 1 word is considered for each step (token), resulting in deterministic completions, while 40 means 40 words are considered at each step. 0 (default) is a special setting meaning no restrictions. 40 generally is a good value. :top_p=0.0 : Float value controlling diversity. Implements nucleus sampling, overriding top_k if set to a value > 0. A good setting is 0.9.\n",
            "\n",
            "\u001b[1mSYNOPSIS\u001b[0m\n",
            "    generate_unconditional_samples.py <flags>\n",
            "\n",
            "\u001b[1mDESCRIPTION\u001b[0m\n",
            "    Run the sample_model :model_name=117M : String, which model to use :seed=None : Integer seed for random number generators, fix seed to reproduce results :nsamples=0 : Number of samples to return, if 0, continues to generate samples indefinately. :batch_size=1 : Number of batches (only affects speed/memory). :length=None : Number of tokens in generated text, if None (default), is determined by model hyperparameters :temperature=1 : Float value controlling randomness in boltzmann distribution. Lower temperature results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive. Higher temperature results in more random completions. :top_k=0 : Integer value controlling diversity. 1 means only 1 word is considered for each step (token), resulting in deterministic completions, while 40 means 40 words are considered at each step. 0 (default) is a special setting meaning no restrictions. 40 generally is a good value. :top_p=0.0 : Float value controlling diversity. Implements nucleus sampling, overriding top_k if set to a value > 0. A good setting is 0.9.\n",
            "\n",
            "\u001b[1mFLAGS\u001b[0m\n",
            "    -m, --model_name=\u001b[4mMODEL_NAME\u001b[0m\n",
            "        Default: '117M'\n",
            "    -s, --seed=\u001b[4mSEED\u001b[0m\n",
            "        Type: Optional[]\n",
            "        Default: None\n",
            "    -n, --nsamples=\u001b[4mNSAMPLES\u001b[0m\n",
            "        Default: 0\n",
            "    -b, --batch_size=\u001b[4mBATCH_SIZE\u001b[0m\n",
            "        Default: 1\n",
            "    -l, --length=\u001b[4mLENGTH\u001b[0m\n",
            "        Type: Optional[]\n",
            "        Default: None\n",
            "    --temperature=\u001b[4mTEMPERATURE\u001b[0m\n",
            "        Default: 1\n",
            "    --top_k=\u001b[4mTOP_K\u001b[0m\n",
            "        Default: 0\n",
            "    --top_p=\u001b[4mTOP_P\u001b[0m\n",
            "        Default: 0.0\n"
          ]
        }
      ],
      "source": [
        "!python3.7 src/generate_unconditional_samples.py -- --help"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}